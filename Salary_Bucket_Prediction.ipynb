{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Salary Bucket Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LOm58z2GLK0f",
        "CN2xFWGX2JT9",
        "o_37B6BG-IEE",
        "f4_3QqMZU_-9",
        "8gfhbu4sUyof",
        "3lta3xPR5bAY",
        "aU9RdB3EpU-B",
        "LGVAv8emF-AV",
        "cw-9-YNP9KFm"
      ],
      "authorship_tag": "ABX9TyMRzMZ1R87YW8hHdfptrnaX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Livy-Li/Global_MLDS_Career_Development_Analysis/blob/main/Salary_Bucket_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtR8JKg92ihw"
      },
      "source": [
        "“The purpose of this assignment is to train, validate, and tune multi-class ordinary classification models that can classify, given a set of survey responses by a data scientist, what a survey respondent’s current yearly compensation bucket is.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOm58z2GLK0f"
      },
      "source": [
        "# Handle Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2xFWGX2JT9"
      },
      "source": [
        "### Explaination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Qxcmdn2RZn"
      },
      "source": [
        "The dataset is imported and presented as a dataframe. After visually inspecting it, it is evident that there are a lot of missing values. For questions where only a single answer can be chosen, each question only exists in one column. If there is a missing value in the column, it is because the respondent did not answer the question. For questions where multiple answers can be chosen, every answer of the question occupies its own column and if the respondent did not select that answer, it is shown as a missing value. Therefore for these questions, a null value in a column means that answer is not selected, it does not necessarily mean the question was not answered by the respondent.\n",
        "\n",
        "The true missing values are from respondents who did not select any answer of a question, meaning they simply skipped the entire question. The rest of the missing values are just pseudo-missing values and we can fill them with ‘0’ later in the encoding stage of data preprocessing.\n",
        "\n",
        "Some helper functions are created to check the number of true missing values of each question and output them into a dataframe. The dataframe shows that some questions have the same amount of true missing values. For example, there are 561 respondents who did not answer Q7-Q15. Did these respondents collectively decide that they want to skip these questions? The answer is no, a further inspection into the survey methodology document reveals the answer. It turned out that participants who answered 'I have never written code' in Q6 were not given Q7-Q19 at all, because these questions are about coding, and these 561 participants could only have answered ‘None’ to these questions. For this reason, we can fill the missing values for these 561 participants for Q7 to Q19 to be ‘None’. The survey methodology document details which questions were not presented to a participant based on his/her answers to other questions, and we can fill these missing answers based on the dependency logic. \n",
        "\n",
        "After filling in these missing answers, there are still some more true missing values existing in some of the questions. These missing values are from respondents who skipped questions at their own will, and we do not know what their potential answers are. The approach to handle these missing values is by creating a new response category called ‘Unknown’ for each question. This approach is straightforward and accurate, there is no guesswork involved, and it would not disrupt the distribution of existing answers. It is suitable to use this approach because there are not many respondents who simply skipped questions for no reason, usually only a few hundred for each question. Given that the entire dataset has over 10k samples, these ‘Unknown’ categories would not have a huge impact. The disadvantage of this approach is that it adds new columns to the dataset without adding new information since the ‘Unknown’ columns are correlated with other columns. This disadvantage is not overly concerning because if the ‘Unknown’ categories do not have a huge impact, they would be filtered out in the feature selection step.\n",
        "\n",
        "After performing the above tasks, the number of true missing values for each question is now zero, and we can move on to the encoding step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_37B6BG-IEE"
      },
      "source": [
        "### User Defined Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfbpxMkg-TaD"
      },
      "source": [
        "# put part A and part B of the same question next to each other\n",
        "def rearrange_columns(df):\n",
        "    column_names = list(df.columns)\n",
        "    new_column_names = []\n",
        "    for name in column_names:\n",
        "        splited = name.split('_')\n",
        "        if len(splited) == 1 or splited[1] != 'B':\n",
        "            new_column_names.append(name)\n",
        "        elif splited[1] == 'B' and len(splited) == 4:\n",
        "            index = new_column_names.index(splited[0]+'_A_'+splited[2]+'_'+splited[3])\n",
        "            new_column_names.insert(index+1, name)\n",
        "        elif splited[1] == 'B' and len(splited) == 3:\n",
        "            index = new_column_names.index(splited[0]+'_A_'+splited[2])\n",
        "            new_column_names.insert(index+1, name)\n",
        "\n",
        "    return new_column_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsrOWj_K-X0o"
      },
      "source": [
        "#extract only the question number of each question, with no part number\n",
        "def get_q_number(df):\n",
        "    column_names = list(df.columns)\n",
        "    new_column_names = []\n",
        "    for name in column_names:\n",
        "        splited = name.split('_')\n",
        "        new_column_names.append(splited[0])\n",
        "    return new_column_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhzD0840-fSQ"
      },
      "source": [
        "#count number of true null values \n",
        "#(i.e. did not choose any provided choices) for each question\n",
        "def count_null_by_question(df):\n",
        "    df1 = df[rearrange_columns(df)]\n",
        "    q_number = get_q_number(df1)\n",
        "    trav = 0\n",
        "    question = []\n",
        "    null_count = []\n",
        "    for i in range(len(q_number)):\n",
        "      if i == trav:\n",
        "        if (i + 1 == len(q_number)) or (q_number[i] != q_number[i+1]):\n",
        "          question.append(q_number[i])\n",
        "          null_count.append(df1.iloc[:,i].isnull().sum())\n",
        "          trav += 1\n",
        "        \n",
        "      else:\n",
        "        if (i + 1 == len(q_number)) or (q_number[i] != q_number[i+1]) :\n",
        "          question.append(q_number[i])\n",
        "          null_count.append(df1.iloc[:,trav:i+1].isnull().all(1).sum())\n",
        "          trav = i+1\n",
        "\n",
        "    return question, null_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nrMjpCW-jxz"
      },
      "source": [
        "#get all columns name that include the question_number\n",
        "def get_question_column_names(question_number, df):\n",
        "  split_column_names = map(lambda column_name: column_name.split('_'), \n",
        "                           df.columns.to_list())\n",
        "  split_question_column_names = filter(lambda split_name: \n",
        "                                       split_name[0] == question_number, \n",
        "                                       split_column_names)\n",
        "  question_column_names = list(map(lambda split_names: '_'.join(split_names), \n",
        "                                   split_question_column_names))\n",
        "\n",
        "  return question_column_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4_3QqMZU_-9"
      },
      "source": [
        "### Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgh_zFk-Id97"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJ2LqRwIzxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f2e454-d31f-4848-f4e6-bd91efba8d49"
      },
      "source": [
        "#read data, and drop the first row (containing the actual question)\n",
        "#drop 'Time from Start to Finish (seconds)' column because it is not relavent\n",
        "df = pd.read_csv('clean_kaggle_data_2020.csv')\n",
        "df = df.drop([0]).reset_index(drop=True)\n",
        "df = df.drop(['Time from Start to Finish (seconds)'], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,206) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "jIp8AGOHVL8t",
        "outputId": "8bb318e3-80aa-44e8-cfbf-2fcd4c8748ea"
      },
      "source": [
        "#take a look at the dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7_Part_1</th>\n",
              "      <th>Q7_Part_2</th>\n",
              "      <th>Q7_Part_3</th>\n",
              "      <th>Q7_Part_4</th>\n",
              "      <th>Q7_Part_5</th>\n",
              "      <th>Q7_Part_6</th>\n",
              "      <th>Q7_Part_7</th>\n",
              "      <th>Q7_Part_8</th>\n",
              "      <th>Q7_Part_9</th>\n",
              "      <th>Q7_Part_10</th>\n",
              "      <th>Q7_Part_11</th>\n",
              "      <th>Q7_Part_12</th>\n",
              "      <th>Q7_OTHER</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9_Part_1</th>\n",
              "      <th>Q9_Part_2</th>\n",
              "      <th>Q9_Part_3</th>\n",
              "      <th>Q9_Part_4</th>\n",
              "      <th>Q9_Part_5</th>\n",
              "      <th>Q9_Part_6</th>\n",
              "      <th>Q9_Part_7</th>\n",
              "      <th>Q9_Part_8</th>\n",
              "      <th>Q9_Part_9</th>\n",
              "      <th>Q9_Part_10</th>\n",
              "      <th>Q9_Part_11</th>\n",
              "      <th>Q9_OTHER</th>\n",
              "      <th>Q10_Part_1</th>\n",
              "      <th>Q10_Part_2</th>\n",
              "      <th>Q10_Part_3</th>\n",
              "      <th>Q10_Part_4</th>\n",
              "      <th>Q10_Part_5</th>\n",
              "      <th>Q10_Part_6</th>\n",
              "      <th>Q10_Part_7</th>\n",
              "      <th>Q10_Part_8</th>\n",
              "      <th>...</th>\n",
              "      <th>Q31_B_Part_9</th>\n",
              "      <th>Q31_B_Part_10</th>\n",
              "      <th>Q31_B_Part_11</th>\n",
              "      <th>Q31_B_Part_12</th>\n",
              "      <th>Q31_B_Part_13</th>\n",
              "      <th>Q31_B_Part_14</th>\n",
              "      <th>Q31_B_OTHER</th>\n",
              "      <th>Q33_B_Part_1</th>\n",
              "      <th>Q33_B_Part_2</th>\n",
              "      <th>Q33_B_Part_3</th>\n",
              "      <th>Q33_B_Part_4</th>\n",
              "      <th>Q33_B_Part_5</th>\n",
              "      <th>Q33_B_Part_6</th>\n",
              "      <th>Q33_B_Part_7</th>\n",
              "      <th>Q33_B_OTHER</th>\n",
              "      <th>Q34_B_Part_1</th>\n",
              "      <th>Q34_B_Part_2</th>\n",
              "      <th>Q34_B_Part_3</th>\n",
              "      <th>Q34_B_Part_4</th>\n",
              "      <th>Q34_B_Part_5</th>\n",
              "      <th>Q34_B_Part_6</th>\n",
              "      <th>Q34_B_Part_7</th>\n",
              "      <th>Q34_B_Part_8</th>\n",
              "      <th>Q34_B_Part_9</th>\n",
              "      <th>Q34_B_Part_10</th>\n",
              "      <th>Q34_B_Part_11</th>\n",
              "      <th>Q34_B_OTHER</th>\n",
              "      <th>Q35_B_Part_1</th>\n",
              "      <th>Q35_B_Part_2</th>\n",
              "      <th>Q35_B_Part_3</th>\n",
              "      <th>Q35_B_Part_4</th>\n",
              "      <th>Q35_B_Part_5</th>\n",
              "      <th>Q35_B_Part_6</th>\n",
              "      <th>Q35_B_Part_7</th>\n",
              "      <th>Q35_B_Part_8</th>\n",
              "      <th>Q35_B_Part_9</th>\n",
              "      <th>Q35_B_Part_10</th>\n",
              "      <th>Q35_B_OTHER</th>\n",
              "      <th>Q24_Encoded</th>\n",
              "      <th>Q24_buckets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30-34</td>\n",
              "      <td>Man</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>Master’s degree</td>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>5-10 years</td>\n",
              "      <td>Python</td>\n",
              "      <td>R</td>\n",
              "      <td>SQL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Python</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Visual Studio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PyCharm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sublime Text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Colab Notebooks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>100,000-124,999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35-39</td>\n",
              "      <td>Man</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>Bachelor’s degree</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>10-20 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Java</td>\n",
              "      <td>Javascript</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bash</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Visual Studio Code (VSCode)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Notepad++</td>\n",
              "      <td>Sublime Text</td>\n",
              "      <td>Vim / Emacs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10,000-19,999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30-34</td>\n",
              "      <td>Man</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>Master’s degree</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>5-10 years</td>\n",
              "      <td>Python</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SQL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bash</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Python</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PyCharm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>125,000-149,999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35-39</td>\n",
              "      <td>Man</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Doctoral degree</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>5-10 years</td>\n",
              "      <td>Python</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SQL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bash</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Python</td>\n",
              "      <td>Jupyter (JupyterLab, Jupyter Notebooks, etc)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PyCharm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sublime Text</td>\n",
              "      <td>Vim / Emacs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kaggle Notebooks</td>\n",
              "      <td>Colab Notebooks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>70,000-79,999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35-39</td>\n",
              "      <td>Man</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>Doctoral degree</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>1-2 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RStudio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30,000-39,999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 356 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Q1   Q2  ... Q24_Encoded      Q24_buckets\n",
              "0  30-34  Man  ...        10.0  100,000-124,999\n",
              "1  35-39  Man  ...         1.0    10,000-19,999\n",
              "2  30-34  Man  ...        11.0  125,000-149,999\n",
              "3  35-39  Man  ...         7.0    70,000-79,999\n",
              "4  35-39  Man  ...         3.0    30,000-39,999\n",
              "\n",
              "[5 rows x 356 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxKhEFyARu2R",
        "outputId": "c60686f3-37a6-4918-e381-206308a8c41e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10729, 356)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG7c1XZDTlhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab2b8bd-ce74-4b3d-d062-a215eab9107d"
      },
      "source": [
        "# display the number of null values for each columns\n",
        "# If the question has multiple parts, the null value means the part is not selected\n",
        "# It does not necessarily mean the question was not answered\n",
        "# therefore for multiple choice question, these numbers are not very helpful\n",
        "df.isnull().sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q1                   0\n",
              "Q2                   0\n",
              "Q3                   0\n",
              "Q4                   0\n",
              "Q5                   0\n",
              "                 ...  \n",
              "Q35_B_Part_9     10481\n",
              "Q35_B_Part_10     9048\n",
              "Q35_B_OTHER      10596\n",
              "Q24_Encoded          0\n",
              "Q24_buckets          0\n",
              "Length: 356, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-QS_EhyFzz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1251
        },
        "outputId": "8a79249b-a75d-4d12-89d6-e9ab205904cc"
      },
      "source": [
        "#we want to display the null values by question\n",
        "#these null counts shows the number of people who skipped all the parts of the questions\n",
        "#these are the true null counts for each question\n",
        "#the function used here can be found in the first section \"User Defined Functions\"\n",
        "question, null_count = count_null_by_question(df)\n",
        "df_q_null = pd.DataFrame(list(zip(question,null_count)), \n",
        "                         columns=['Question','Null Count']) \n",
        "df_q_null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Null Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q7</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q8</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q9</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q10</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Q11</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Q12</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Q13</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Q14</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Q15</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Q16</td>\n",
              "      <td>1616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Q17</td>\n",
              "      <td>1616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Q18</td>\n",
              "      <td>6831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Q19</td>\n",
              "      <td>8002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Q20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Q21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Q22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Q23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Q24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Q25</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Q26</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Q27</td>\n",
              "      <td>3200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Q28</td>\n",
              "      <td>3282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Q29</td>\n",
              "      <td>574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Q30</td>\n",
              "      <td>7216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Q31</td>\n",
              "      <td>683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Q32</td>\n",
              "      <td>9231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Q33</td>\n",
              "      <td>801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Q34</td>\n",
              "      <td>6221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Q35</td>\n",
              "      <td>948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Q36</td>\n",
              "      <td>4104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Q37</td>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Q38</td>\n",
              "      <td>1253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Q39</td>\n",
              "      <td>1306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Q24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Question  Null Count\n",
              "0        Q1           0\n",
              "1        Q2           0\n",
              "2        Q3           0\n",
              "3        Q4           0\n",
              "4        Q5           0\n",
              "5        Q6           0\n",
              "6        Q7         561\n",
              "7        Q8         561\n",
              "8        Q9         561\n",
              "9       Q10         561\n",
              "10      Q11         561\n",
              "11      Q12         561\n",
              "12      Q13         561\n",
              "13      Q14         561\n",
              "14      Q15         561\n",
              "15      Q16        1616\n",
              "16      Q17        1616\n",
              "17      Q18        6831\n",
              "18      Q19        8002\n",
              "19      Q20           0\n",
              "20      Q21           0\n",
              "21      Q22           0\n",
              "22      Q23           0\n",
              "23      Q24           0\n",
              "24      Q25         159\n",
              "25      Q26         288\n",
              "26      Q27        3200\n",
              "27      Q28        3282\n",
              "28      Q29         574\n",
              "29      Q30        7216\n",
              "30      Q31         683\n",
              "31      Q32        9231\n",
              "32      Q33         801\n",
              "33      Q34        6221\n",
              "34      Q35         948\n",
              "35      Q36        4104\n",
              "36      Q37        1002\n",
              "37      Q38        1253\n",
              "38      Q39        1306\n",
              "39      Q24           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwx4y4yJmmIX"
      },
      "source": [
        "#people who answered 'I have never written code' in Q6 were not asked Q7-Q19 (they are about coding)\n",
        "#we can fill the NaN value with approprite choice for those questions such as 'None' and 'Never', based on the choices provided by the questions \n",
        "df.loc[df['Q6'] == 'I have never written code', ['Q7_Part_12','Q8','Q9_Part_11','Q10_Part_13','Q11','Q12_Part_3','Q14_Part_11','Q16_Part_15','Q17_Part_11','Q18_Part_6','Q19_Part_5']] = 'None'\n",
        "df.loc[df['Q6'] == 'I have never written code', ['Q13']] = 'Never'\n",
        "df.loc[df['Q6'] == 'I have never written code', ['Q15']] = 'I do not use machine learning methods'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDslsrQ1cGd_"
      },
      "source": [
        "#people who answered 'I do not use machine learning methods' in Q15 were not asked Q16-Q19 (they are about machine learning)\n",
        "#we can fill the NaN value with 'None' for those questions\n",
        "df.loc[df['Q15'] == 'I do not use machine learning methods', ['Q16_Part_15','Q17_Part_11','Q18_Part_6','Q19_Part_5']] = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl6JbEQoempD"
      },
      "source": [
        "#People who answered 'Convolutional Neural Networks'and 'Generative Adversarial Networks' in Q17 were given Q18 to answer\n",
        "#Therefore for people who did not choose those two choices, we can fill their answer in Q18 as 'None' (because they were not presented with Q18)\n",
        "\n",
        "df.loc[(df['Q17_Part_7'].isnull())&(df['Q17_Part_8'].isnull()),['Q18_Part_6']] = 'None'\n",
        "\n",
        "#People who answered 'Recurrent Neural Networks'and 'Transformer Networks (BERT, gpt-3, etc)' in Q17 were given Q19 to answer\n",
        "#Therefore for people who did not choose those two choices, we can fill their answer in Q19 as 'None' (because they were not presented with Q19)\n",
        "\n",
        "df.loc[(df['Q17_Part_9'].isnull())&(df['Q17_Part_10'].isnull()),['Q19_Part_5']] = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4vNpn0JkQ88"
      },
      "source": [
        "#questions that are independent of other questions\n",
        "#a nan value means the respondent was presented with the question but did not answer it\n",
        "#therefore the answer to the question is filled as 'Unknown' if it is a single choice question\n",
        "#for multiple choice questions, a new column is created and 'Unknown' is filled as an answer\n",
        "#the missing values are relatively small for these questions, the largest one is Q36\n",
        "\n",
        "df.loc[df['Q25'].isnull(), 'Q25'] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q26_A_OTHER')+1,'Q26_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q26', df)].isnull().all(1), ['Q26_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q29_A_OTHER')+1,'Q29_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q29', df)].isnull().all(1), ['Q29_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q31_A_OTHER')+1,'Q31_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q31', df)].isnull().all(1), ['Q31_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q33_A_OTHER')+1,'Q33_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q33', df)].isnull().all(1), ['Q33_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q35_A_OTHER')+1,'Q35_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q35', df)].isnull().all(1), ['Q35_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q36_OTHER')+1,'Q36_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q36', df)].isnull().all(1), ['Q36_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q37_OTHER')+1,'Q37_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q37', df)].isnull().all(1), ['Q37_MISSING']] = 'Unknown'\n",
        "\n",
        "df.loc[df['Q38'].isnull(), 'Q38'] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q39_OTHER')+1,'Q39_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q39', df)].isnull().all(1), ['Q39_MISSING']] = 'Unknown'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhTC_Z8_ejX2"
      },
      "source": [
        "#People who answered 'Amazon Web Services (AWS)', 'Microsoft Azure' and 'Google Cloud Platform (GCP)'in Q26(AorB) were given Q27(AorB) and Q28(AorB) to answer\n",
        "#Therefore for people who answered Q26 but did not choose those three choices, we can fill their answer in Q27 and Q28 as 'None'\n",
        "\n",
        "df.loc[(\n",
        "    df['Q26_MISSING'].isnull()&df['Q26_B_Part_1'].isnull()&df['Q26_B_Part_2'].isnull()&\n",
        "    df['Q26_B_Part_3'].isnull()&df['Q26_B_Part_4'].isnull()&df['Q26_B_Part_5'].isnull()&\n",
        "    df['Q26_B_Part_6'].isnull()&df['Q26_B_Part_7'].isnull()&df['Q26_B_Part_8'].isnull()&\n",
        "    df['Q26_B_Part_9'].isnull()&df['Q26_B_Part_10'].isnull()&df['Q26_B_Part_11'].isnull()&\n",
        "    df['Q26_B_OTHER'].isnull()&df['Q26_A_Part_1'].isnull()&df['Q26_A_Part_2'].isnull()&df['Q26_A_Part_3'].isnull()\n",
        "    ),['Q27_A_Part_11','Q28_A_Part_10']] = 'None'\n",
        "\n",
        "df.loc[(\n",
        "    df['Q26_MISSING'].isnull()&df['Q26_A_Part_1'].isnull()&df['Q26_A_Part_2'].isnull()&\n",
        "    df['Q26_A_Part_3'].isnull()&df['Q26_A_Part_4'].isnull()&df['Q26_A_Part_5'].isnull()&\n",
        "    df['Q26_A_Part_6'].isnull()&df['Q26_A_Part_7'].isnull()&df['Q26_A_Part_8'].isnull()&\n",
        "    df['Q26_A_Part_9'].isnull()&df['Q26_A_Part_10'].isnull()&df['Q26_A_Part_11'].isnull()&\n",
        "    df['Q26_A_OTHER'].isnull()&df['Q26_B_Part_1'].isnull()&df['Q26_B_Part_2'].isnull()&df['Q26_B_Part_3'].isnull()\n",
        "    ),['Q27_B_Part_11','Q28_B_Part_10']] = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVJ7EtAujd2_"
      },
      "source": [
        "#Q30 was only asked to respondents that selected more than one choice for Q29A\n",
        "#Therefore for people who answered Q29A but only choose one, we can fill their answer in Q30 as the same as Q29A\n",
        "#for people who answered Q29B, we can fill their answer in Q30 as 'None'\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_1')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'MySQL'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_2')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'PostgreSQL'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_3')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'SQLite'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_4')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Oracle Database'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_5')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'MongoDB'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_6')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Snowflake'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_7')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'IBM Db2'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_8')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Microsoft SQL Server'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_9')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Microsoft Access'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_10')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Microsoft Azure Data Lake Storage'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_11')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Amazon Redshift'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_12')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Amazon Athena'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_13')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Amazon DynamoDB'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_14')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Google Cloud BigQuery'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_15')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Google Cloud SQL'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_16')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Google Cloud Firestore'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_Part_17')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'None'\n",
        "\n",
        "test_list = get_question_column_names('Q29', df)\n",
        "test_list.remove('Q29_A_OTHER')\n",
        "df.loc[df[test_list].isnull().all(1),['Q30']] = 'Other'\n",
        "\n",
        "\n",
        "df.loc[(\n",
        "    df['Q29_MISSING'].isnull()&df['Q29_A_Part_1'].isnull()&df['Q29_A_Part_2'].isnull()&\n",
        "    df['Q29_A_Part_3'].isnull()&df['Q29_A_Part_4'].isnull()&df['Q29_A_Part_5'].isnull()&\n",
        "    df['Q29_A_Part_6'].isnull()&df['Q29_A_Part_7'].isnull()&df['Q29_A_Part_8'].isnull()&\n",
        "    df['Q29_A_Part_9'].isnull()&df['Q29_A_Part_10'].isnull()&df['Q29_A_Part_11'].isnull()&\n",
        "    df['Q29_A_Part_12'].isnull()&df['Q29_A_Part_13'].isnull()&df['Q29_A_Part_14'].isnull()&\n",
        "    df['Q29_A_Part_15'].isnull()&df['Q29_A_Part_16'].isnull()&df['Q29_A_Part_17'].isnull()&\n",
        "    df['Q29_A_OTHER'].isnull()\n",
        "    ),['Q30']] = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqFcI5-p48n0"
      },
      "source": [
        "#Q32 was only asked to respondents that selected more than one choice for Q31A.\n",
        "#Therefore for people who answered Q31A but only choose one, we can fill their answer in Q32 as the same as Q31A\n",
        "#for people who answered Q31B, we can fill their answer in Q32 as 'None'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_1')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = '​Amazon QuickSight'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_2')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Microsoft Power BI'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_3')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Google Data Studio'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_4')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Looker'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_5')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Tableau'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_6')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Salesforce'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_7')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Einstein Analytics'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_8')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Qlik'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_9')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Domo'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_10')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'TIBCO Spotfire'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_11')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Alteryx'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_12')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Sisense'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_13')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'SAP Analytics Cloud'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_Part_14')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'None'\n",
        "\n",
        "test_list = get_question_column_names('Q31', df)\n",
        "test_list.remove('Q31_A_OTHER')\n",
        "df.loc[df[test_list].isnull().all(1),['Q32']] = 'Other'\n",
        "\n",
        "\n",
        "df.loc[(\n",
        "    df['Q31_MISSING'].isnull()&df['Q31_A_Part_1'].isnull()&df['Q31_A_Part_2'].isnull()&\n",
        "    df['Q31_A_Part_3'].isnull()&df['Q31_A_Part_4'].isnull()&df['Q31_A_Part_5'].isnull()&\n",
        "    df['Q31_A_Part_6'].isnull()&df['Q31_A_Part_7'].isnull()&df['Q31_A_Part_8'].isnull()&\n",
        "    df['Q31_A_Part_9'].isnull()&df['Q31_A_Part_10'].isnull()&df['Q31_A_Part_11'].isnull()&\n",
        "    df['Q31_A_Part_12'].isnull()&df['Q31_A_Part_13'].isnull()&df['Q31_A_Part_14'].isnull()&\n",
        "    df['Q31_A_OTHER'].isnull()\n",
        "    ),['Q32']] = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P10ztPre9pCp"
      },
      "source": [
        "#Q34 was only asked to respondents that answered affirmatively to Q33\n",
        "#Therefore for people who answered Q33 with 'None', we can fill their answer in Q34 'None'\n",
        "\n",
        "test_list = get_question_column_names('Q33', df)\n",
        "test_list.remove('Q33_A_Part_7')\n",
        "df.loc[df[test_list].isnull().all(1),['Q34_A_Part_11']] = 'None'\n",
        "\n",
        "test_list = get_question_column_names('Q33', df)\n",
        "test_list.remove('Q33_B_Part_7')\n",
        "df.loc[df[test_list].isnull().all(1),['Q34_B_Part_11']] = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejqv283pr8Yv"
      },
      "source": [
        "#The rest of the NAN are the people who were presented with the questions but skipped them\n",
        "#Therefore the answer to the question is filled as 'Unknown'\n",
        "df.insert(df.columns.to_list().index('Q18_OTHER')+1,'Q18_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q18', df)].isnull().all(1), ['Q18_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q19_OTHER')+1,'Q19_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q19', df)].isnull().all(1), ['Q19_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q27_A_OTHER')+1,'Q27_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q27', df)].isnull().all(1), ['Q27_MISSING']] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q28_A_OTHER')+1,'Q28_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q28', df)].isnull().all(1), ['Q28_MISSING']] = 'Unknown'\n",
        "\n",
        "df.loc[df['Q30'].isnull(), 'Q30'] = 'Unknown'\n",
        "\n",
        "df.loc[df['Q32'].isnull(), 'Q32'] = 'Unknown'\n",
        "\n",
        "df.insert(df.columns.to_list().index('Q34_A_OTHER')+1,'Q34_MISSING',np.nan)\n",
        "df.loc[df[get_question_column_names('Q34', df)].isnull().all(1), ['Q34_MISSING']] = 'Unknown'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1251
        },
        "id": "arn8u7YsUZ7A",
        "outputId": "24f0395f-22aa-4877-9e4f-27a67c9db0f1"
      },
      "source": [
        "#Check again, all the NaN value by question are now zero!\n",
        "question, null_count = count_null_by_question(df)\n",
        "df_q_null = pd.DataFrame(list(zip(question,null_count)), columns=['Question','Null Count']) \n",
        "df_q_null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Null Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Q11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Q12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Q13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Q14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Q15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Q16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Q17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Q18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Q19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Q20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Q21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Q22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Q23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Q24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Q25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Q26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Q27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Q28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Q29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Q30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Q31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Q32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Q33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Q34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Q35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Q36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Q37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Q38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Q39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Q24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Question  Null Count\n",
              "0        Q1           0\n",
              "1        Q2           0\n",
              "2        Q3           0\n",
              "3        Q4           0\n",
              "4        Q5           0\n",
              "5        Q6           0\n",
              "6        Q7           0\n",
              "7        Q8           0\n",
              "8        Q9           0\n",
              "9       Q10           0\n",
              "10      Q11           0\n",
              "11      Q12           0\n",
              "12      Q13           0\n",
              "13      Q14           0\n",
              "14      Q15           0\n",
              "15      Q16           0\n",
              "16      Q17           0\n",
              "17      Q18           0\n",
              "18      Q19           0\n",
              "19      Q20           0\n",
              "20      Q21           0\n",
              "21      Q22           0\n",
              "22      Q23           0\n",
              "23      Q24           0\n",
              "24      Q25           0\n",
              "25      Q26           0\n",
              "26      Q27           0\n",
              "27      Q28           0\n",
              "28      Q29           0\n",
              "29      Q30           0\n",
              "30      Q31           0\n",
              "31      Q32           0\n",
              "32      Q33           0\n",
              "33      Q34           0\n",
              "34      Q35           0\n",
              "35      Q36           0\n",
              "36      Q37           0\n",
              "37      Q38           0\n",
              "38      Q39           0\n",
              "39      Q24           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfhbu4sUyof"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78kX-71a2trY"
      },
      "source": [
        "The features and targets of the dataset are separated in this step and the encoding is performed on the features. The encoding methods used are Ordinal Encoding and One Hot Encoding. Ordinal Encoding is used for questions where only one answer can be chosen that have ordered responses. For example, Q1 asks for the age of the participants. The answers are grouped into different age groups and these age groups can be ordered from the youngest (18-21) to the oldest (70+). By using Ordinal Encoding, smaller numbers are assigned for younger age groups, and larger numbers are assigned for older age groups. The advantage of this Ordinal Encoding is that it preserves the ordered relationship between groups and this information can be valuable for making predictions. In the context of this project, the increase in age of the participants can be positively correlated with increasing salaries, as people tend to earn more with experience and seniority. The disadvantage of Ordinal Encoding is that between different questions the encoding scales are not comparable. For example, a value of 3 representing the age group ‘25-29’ in Q1 is not comparable to a value of 3 representing ‘Bachelor’s degree’ in Q4. In addition, this causes a difference in maximum and minimum values between questions, because some of the questions have more groups than others. We can attempt to reduce some of the disadvantages related to Ordinal Encoding later by scaling and regularizing features.\n",
        "\n",
        "One Hot Encoding is used for questions where only one answer can be chosen that do not have ordered responses, such as gender (Q2) and country of residence (Q3). By using One Hot Encoding, each unique response of a question becomes a new column, and the columns are filled with binary integers (0 or 1) to indicate if the response is selected. The advantage of One Hot Encoding is that it can represent non-ordinal data using binary integers without losing information. The disadvantage is low information density. The result of One Hot Encoding questions where one answer can be chosen is stored in multiple different columns instead of a sparse matrix to keep a consistent form with the questions where multiple answers can be chosen. Therefore extra columns are created filled with mostly zeros, especially for questions with a considerable amount of categories such as country of residence (Q3).\n",
        "\n",
        "Finally, we can fill all the missing values with zeros for questions where multiple answers can be chosen and then replace the strings with 1. The results are similar to One Hot Encoding: the binary integers are used to indicate whether a given option is selected or not.  The resulting features have 509 columns. At this point, the dataframe has no missing values anymore.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWUMvLmLMwVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e929fe-22b5-440a-d131-3f5629810dc6"
      },
      "source": [
        "!pip install category_encoders\n",
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_XP4SeiMudf"
      },
      "source": [
        "#Use abbreviations for countries with longer names\n",
        "df['Q3'] = df['Q3'].replace({\"United States of America\":\"US\",\n",
        "                                   \"United Arab Emirates\":\"UAE\",\n",
        "                                   \"United Kingdom of Great Britain and Northern Ireland\":\"UK\",\n",
        "                                   \"Iran, Islamic Republic of...\":\"Iran\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ksufYVL4y0"
      },
      "source": [
        "#separate features and target\n",
        "df_features = df.drop(['Q24','Q24_Encoded','Q24_buckets'],axis=1)\n",
        "df_targets = df[['Q24_buckets','Q24_Encoded']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZuJAJpQUtc2",
        "outputId": "d5bbbe20-8d36-4f8e-bd63-53d331428560"
      },
      "source": [
        "#Encode ordinal data with OrdinalEncoder, including age (Q1), education (Q4)\n",
        "#programming years(Q6),TPU using times (Q13), machine learning using times (Q15)\n",
        "#size of the company (Q20), work force size (Q21), current usage of maching learning (Q22)\n",
        "#spending on ml tools (Q25)\n",
        "#all questions mentioned above are single choice questions\n",
        "\n",
        "encoderQ1= ce.OrdinalEncoder(cols=['Q1'],return_df=True,\n",
        "                           mapping=[{'col':'Q1',\n",
        "'mapping':{'18-21':1,'22-24':2,'25-29':3,'30-34':4,'35-39':5,'40-44':6,\n",
        "           '45-49':7,'50-54':8,'55-59':9,'60-69':10,'70+':11}}])\n",
        "df_features = encoderQ1.fit_transform(df_features)\n",
        "\n",
        "encoderQ4= ce.OrdinalEncoder(cols=['Q4'],return_df=True,\n",
        "                           mapping=[{'col':'Q4',\n",
        "'mapping':{'I prefer not to answer':0,'No formal education past high school':1,\n",
        "           'Some college/university study without earning a bachelor’s degree':2,\n",
        "           'Bachelor’s degree':3,'Master’s degree':4,'Doctoral degree':5,\n",
        "           'Professional degree':6}}])\n",
        "df_features = encoderQ4.fit_transform(df_features)\n",
        "\n",
        "encoderQ6= ce.OrdinalEncoder(cols=['Q6'],return_df=True,\n",
        "                           mapping=[{'col':'Q6',\n",
        "'mapping':{'I have never written code':1,'< 1 years':2,'1-2 years':3,'3-5 years':4,\n",
        "           '5-10 years':5,'10-20 years':6,'20+ years':7}}])\n",
        "df_features = encoderQ6.fit_transform(df_features)\n",
        "\n",
        "encoderQ13= ce.OrdinalEncoder(cols=['Q13'],return_df=True,\n",
        "                           mapping=[{'col':'Q13',\n",
        "'mapping':{'Never':1,'Once':2,'2-5 times':3,'6-25 times':4,'More than 25 times':5}}])\n",
        "df_features = encoderQ13.fit_transform(df_features)\n",
        "\n",
        "encoderQ15= ce.OrdinalEncoder(cols=['Q15'],return_df=True,\n",
        "                           mapping=[{'col':'Q15',\n",
        "'mapping':{'I do not use machine learning methods':1,'Under 1 year':2,'1-2 years':3,\n",
        "           '2-3 years':4,'3-4 years':5,'4-5 years':6,'5-10 years':7,\n",
        "           '10-20 years':8,'20 or more years':9}}])\n",
        "df_features = encoderQ15.fit_transform(df_features)\n",
        "\n",
        "encoderQ20= ce.OrdinalEncoder(cols=['Q20'],return_df=True,\n",
        "                           mapping=[{'col':'Q20',\n",
        "'mapping':{'0-49 employees':1,'50-249 employees':2,'250-999 employees':3,\n",
        "           '1000-9,999 employees':4,'10,000 or more employees':5}}])\n",
        "df_features = encoderQ20.fit_transform(df_features)\n",
        "\n",
        "encoderQ21= ce.OrdinalEncoder(cols=['Q21'],return_df=True,\n",
        "                           mapping=[{'col':'Q21',\n",
        "'mapping':{'0':1,'1-2':2,'3-4':3,'5-9':4,'10-14':5,'15-19':6,'20+':7}}])\n",
        "df_features = encoderQ21.fit_transform(df_features)\n",
        "\n",
        "encoderQ22= ce.OrdinalEncoder(cols=['Q22'],return_df=True,\n",
        "                           mapping=[{'col':'Q22',\n",
        "'mapping':{'I do not know':0,'No (we do not use ML methods)':1,\n",
        "           'We are exploring ML methods (and may one day put a model into production)':2,\n",
        "           'We use ML methods for generating insights (but do not put working models into production)':3,\n",
        "           'We recently started using ML methods (i.e., models in production for less than 2 years)':4,\n",
        "           'We have well established ML methods (i.e., models in production for more than 2 years)':5}}])\n",
        "df_features = encoderQ22.fit_transform(df_features)\n",
        "\n",
        "encoderQ25= ce.OrdinalEncoder(cols=['Q25'],return_df=True,\n",
        "                           mapping=[{'col':'Q25',\n",
        "'mapping':{'Unknown':0,'$0 ($USD)':1,'$1-$99':2,'$100-$999':3,'$1000-$9,999':4,\n",
        "           '$10,000-$99,999':5,'$100,000 or more ($USD)':6}}])\n",
        "df_features = encoderQ25.fit_transform(df_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a42BOQmTQWG",
        "outputId": "4c60a1b7-6474-45c7-9bc6-34e4d837682a"
      },
      "source": [
        "#The rest of the single choice questions (Q2,Q3,Q5,Q8,Q11,Q30,Q32,Q38) are encoded with OneHotEncoder\n",
        "question_list = ['Q2','Q3','Q5','Q8','Q11','Q30','Q32','Q38']\n",
        "hot_encoder=ce.OneHotEncoder(cols=question_list,handle_unknown='return_nan',return_df=True,use_cat_names=True)\n",
        "df_features = hot_encoder.fit_transform(df_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqYWZeftykkV"
      },
      "source": [
        "#all it left are the multiple choice questions\n",
        "#we can replace the nan values with number 0\n",
        "#we can replace the strings with number 1\n",
        "#the results for these question are similar to OneHotEncoding for single choice questions\n",
        "df_features = df_features.fillna(0)\n",
        "column_list = df_features.columns.to_list()\n",
        "for li in column_list:\n",
        "    df_features[li] = pd.to_numeric(df_features[li], errors='coerce').fillna(1).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RaRZoYn4YtQ",
        "outputId": "d5708990-d007-45b2-f17a-02f713560d16"
      },
      "source": [
        "#check the info of the df_features now\n",
        "#there are no null values\n",
        "#all data type are int, meaning encoding is done successfully\n",
        "df_features.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10729 entries, 0 to 10728\n",
            "Columns: 509 entries, Q1 to Q35_B_OTHER\n",
            "dtypes: int64(509)\n",
            "memory usage: 41.7 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlSIDNEJvDpa",
        "outputId": "21615ae9-6b7b-4f3e-b454-38ba277f5cc3"
      },
      "source": [
        "#look at the df again just to check\n",
        "df_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10729, 509)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lta3xPR5bAY"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xekpPIaE3BUL"
      },
      "source": [
        "The tools used to visualize feature importance are the Random Forest Classifier and correlation heatmap. The dataset is separated into train and test sets and only the training set is used in the Random Forest Model. Random Forest Classifier employs numerous decision trees working as an ensemble to make class predictions. It is used because it supports multiclass datasets and is considered to be accurate and robust. It has a convenient impurity-based feature importances property built into the model that we can use to visualize feature importance. However, Random Forest works better with an uncorrelated dataset, therefore a correlation heatmap is also generated as a supplement. The plots are presented below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFeQJu-fnLfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1410f1f9-a37f-44b3-ae9a-7004accc6cda"
      },
      "source": [
        "!pip install heatmapz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: heatmapz in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from heatmapz) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from heatmapz) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from heatmapz) (0.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->heatmapz) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->heatmapz) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->heatmapz) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->heatmapz) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->heatmapz) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->heatmapz) (2.4.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->heatmapz) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->heatmapz) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip3l9ToRCc_z"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from heatmap import heatmap, corrplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6tyfboxlqe-"
      },
      "source": [
        "#split train and test sets before applying any ml methods\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_features, df_targets, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlT6LsAGCsVb",
        "outputId": "f6428bb3-e67f-4a16-e2bc-df543cec7c9f"
      },
      "source": [
        "#Using random forest classifier to explore feature importance\n",
        "reg = RandomForestClassifier()\n",
        "reg.fit(X_train, y_train['Q24_buckets'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVrlLfN0Cy-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "da7b775f-0081-4550-bf5c-49a5f43b2e56"
      },
      "source": [
        "#look at feature importance given by random forest regressor\n",
        "df_feature_importance = pd.DataFrame(reg.feature_importances_, index=X_train.columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n",
        "df_feature_importance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Q1</th>\n",
              "      <td>0.028464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q6</th>\n",
              "      <td>0.022606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q20</th>\n",
              "      <td>0.020162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q3_US</th>\n",
              "      <td>0.019527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q25</th>\n",
              "      <td>0.018495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q32_Sisense</th>\n",
              "      <td>0.000059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q30_Google Cloud Firestore</th>\n",
              "      <td>0.000035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q3_Nepal</th>\n",
              "      <td>0.000004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q18_MISSING</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q19_MISSING</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>509 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            feature importance\n",
              "Q1                                    0.028464\n",
              "Q6                                    0.022606\n",
              "Q20                                   0.020162\n",
              "Q3_US                                 0.019527\n",
              "Q25                                   0.018495\n",
              "...                                        ...\n",
              "Q32_Sisense                           0.000059\n",
              "Q30_Google Cloud Firestore            0.000035\n",
              "Q3_Nepal                              0.000004\n",
              "Q18_MISSING                           0.000000\n",
              "Q19_MISSING                           0.000000\n",
              "\n",
              "[509 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "wiUb4bLlD-Fi",
        "outputId": "a7c10719-ac78-4ef8-88f1-b969c22e0432"
      },
      "source": [
        "#Visualize the 30 most important features given by the random forest regression\n",
        "df_feature_importance30 = df_feature_importance.head(30)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(df_feature_importance30.index,df_feature_importance30['feature importance'])\n",
        "plt.xticks(rotation=-90)\n",
        "plt.title('Visualize the 30 most important features')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Features importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "mP-vKOsk5e5S",
        "outputId": "fab84b6d-8f08-434c-92ce-17be5a6a2678"
      },
      "source": [
        "#look at the correlation plot between the 15 most important features and the target\n",
        "first15 = df_feature_importance.head(15).index.to_list()\n",
        "df_feature_15 = pd.concat([X_train[first15],y_train], axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "corrplot(df_feature_15.corr(), size_scale=300);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "WUqVL7HONpkm",
        "outputId": "43e2a500-92cf-4174-c629-9452018f077c"
      },
      "source": [
        "df_features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2_Man</th>\n",
              "      <th>Q2_Woman</th>\n",
              "      <th>Q2_Nonbinary</th>\n",
              "      <th>Q2_Prefer not to say</th>\n",
              "      <th>Q2_Prefer to self-describe</th>\n",
              "      <th>Q3_US</th>\n",
              "      <th>Q3_Argentina</th>\n",
              "      <th>Q3_Germany</th>\n",
              "      <th>Q3_Canada</th>\n",
              "      <th>Q3_Switzerland</th>\n",
              "      <th>Q3_India</th>\n",
              "      <th>Q3_Russia</th>\n",
              "      <th>Q3_South Africa</th>\n",
              "      <th>Q3_Netherlands</th>\n",
              "      <th>Q3_Pakistan</th>\n",
              "      <th>Q3_Other</th>\n",
              "      <th>Q3_Indonesia</th>\n",
              "      <th>Q3_Belarus</th>\n",
              "      <th>Q3_Ukraine</th>\n",
              "      <th>Q3_Saudi Arabia</th>\n",
              "      <th>Q3_Taiwan</th>\n",
              "      <th>Q3_China</th>\n",
              "      <th>Q3_Italy</th>\n",
              "      <th>Q3_UAE</th>\n",
              "      <th>Q3_Colombia</th>\n",
              "      <th>Q3_Viet Nam</th>\n",
              "      <th>Q3_UK</th>\n",
              "      <th>Q3_Egypt</th>\n",
              "      <th>Q3_Brazil</th>\n",
              "      <th>Q3_Mexico</th>\n",
              "      <th>Q3_Poland</th>\n",
              "      <th>Q3_Nigeria</th>\n",
              "      <th>Q3_France</th>\n",
              "      <th>Q3_Belgium</th>\n",
              "      <th>Q3_Turkey</th>\n",
              "      <th>Q3_Spain</th>\n",
              "      <th>Q3_Iran</th>\n",
              "      <th>Q3_Japan</th>\n",
              "      <th>Q3_Tunisia</th>\n",
              "      <th>...</th>\n",
              "      <th>Q31_B_Part_7</th>\n",
              "      <th>Q31_B_Part_8</th>\n",
              "      <th>Q31_B_Part_9</th>\n",
              "      <th>Q31_B_Part_10</th>\n",
              "      <th>Q31_B_Part_11</th>\n",
              "      <th>Q31_B_Part_12</th>\n",
              "      <th>Q31_B_Part_13</th>\n",
              "      <th>Q31_B_Part_14</th>\n",
              "      <th>Q31_B_OTHER</th>\n",
              "      <th>Q33_B_Part_1</th>\n",
              "      <th>Q33_B_Part_2</th>\n",
              "      <th>Q33_B_Part_3</th>\n",
              "      <th>Q33_B_Part_4</th>\n",
              "      <th>Q33_B_Part_5</th>\n",
              "      <th>Q33_B_Part_6</th>\n",
              "      <th>Q33_B_Part_7</th>\n",
              "      <th>Q33_B_OTHER</th>\n",
              "      <th>Q34_B_Part_1</th>\n",
              "      <th>Q34_B_Part_2</th>\n",
              "      <th>Q34_B_Part_3</th>\n",
              "      <th>Q34_B_Part_4</th>\n",
              "      <th>Q34_B_Part_5</th>\n",
              "      <th>Q34_B_Part_6</th>\n",
              "      <th>Q34_B_Part_7</th>\n",
              "      <th>Q34_B_Part_8</th>\n",
              "      <th>Q34_B_Part_9</th>\n",
              "      <th>Q34_B_Part_10</th>\n",
              "      <th>Q34_B_Part_11</th>\n",
              "      <th>Q34_B_OTHER</th>\n",
              "      <th>Q35_B_Part_1</th>\n",
              "      <th>Q35_B_Part_2</th>\n",
              "      <th>Q35_B_Part_3</th>\n",
              "      <th>Q35_B_Part_4</th>\n",
              "      <th>Q35_B_Part_5</th>\n",
              "      <th>Q35_B_Part_6</th>\n",
              "      <th>Q35_B_Part_7</th>\n",
              "      <th>Q35_B_Part_8</th>\n",
              "      <th>Q35_B_Part_9</th>\n",
              "      <th>Q35_B_Part_10</th>\n",
              "      <th>Q35_B_OTHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 509 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Q1  Q2_Man  Q2_Woman  ...  Q35_B_Part_9  Q35_B_Part_10  Q35_B_OTHER\n",
              "0   4       1         0  ...             0              0            0\n",
              "1   5       1         0  ...             0              1            0\n",
              "2   4       1         0  ...             0              0            0\n",
              "3   5       1         0  ...             0              0            0\n",
              "4   5       1         0  ...             0              0            0\n",
              "\n",
              "[5 rows x 509 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXb48I403Lx1"
      },
      "source": [
        "The first figure shows the 30 most important features given by the Random Forest Cassifier. The top 5 features that are most related to a survey respondent’s yearly compensation are age (Q1), programming experience (Q6), machine learning experience (Q15), size of company (Q20), and whether or not the respondent currently resides in the US (Q3 - US).  The correlation plot only uses the top 15 features plus the encoded target (Q24_Encoded), and there is a colour bar indicating the degree of correlation. The only negative correlation shown is if a respondent lives in India. The participant’s age, programming experience and machine learning experience are naturally more correlated to each other than other features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9RdB3EpU-B"
      },
      "source": [
        "#Feature Engineering and Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCaE3rJN3kJq"
      },
      "source": [
        "Feature engineering is important because it better prepares the dataset to represent the underlying question. To a certain degree, feature engineering dictates how well the model prediction can be, and how insightfully the result can be interpreted. Because the dataset has over 500 columns for features, feature engineering can be applied to reduce the number of features.  In this case, reducing the number of features can greatly reduce the amount of time needed to process the dataset when fitting models. Since encoding country of residence data generated a lot of new columns and only two countries (US and India) rank among the top 30 in feature importance, we can group all the other countries into the ‘Q3_Other’ column, thereby eliminating more than 50 columns.\n",
        "\n",
        "Feature selection can further reduce the number of features in our dataset. It is performed by using Ordinal Logistic Regression with L1 penalty. Ordinal Logistic Regression is implemented using the Logistic Regression Model from sklearn as a binary classifier. The target has 15 different salary buckets, therefore the binary classifier needs to run 14 times, each time changing the class label of samples to be either 0 or 1. For example, the first time the samples belong to the salary bucket ‘0-9999’ are set to class 0, and the samples belong to the rest of the salary buckets are set to class 1. The second time the samples belong to the salary bucket ‘0-9999’ and ‘10000-19999’ are set to class 0, and the samples belong to the rest of the salary buckets are set to class 1.\n",
        "\n",
        "Because of the use of the L1 penalty term, not all features are selected when fitting the model. The SelectFromModel transformer can select all features with non-zero coefficients, and return a boolean value of whether a feature is selected using .get_support(). Only features that have non-zero coefficients for all 14 binary classifiers are selected. The number of columns selected is slightly different each time, at around 60 columns.\n",
        "\n",
        "Compared to the 509 columns before feature engineering, the size of the features has been greatly reduced. This is beneficial because it reduces the complexity of the dataset and can improve efficiency in later stages. However, this might reduce the accuracy of our prediction results to some degree, so the criterion of feature selection can be loosened if the final prediction accuracy is too low after we implement the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTiUVSE5QqHb",
        "outputId": "b1d56438-d14a-4823-82e4-7a1ab1123c9c"
      },
      "source": [
        "#feature engineering: grouping all countries except US and India in to Others\n",
        "#reducing 52 columns\n",
        "\n",
        "df_features.loc[(df_features['Q3_US'] == 0) & (df_features['Q3_India'] == 0),['Q3_Other']] = 1\n",
        "\n",
        "df_features = df_features.drop(['Q3_Argentina','Q3_Germany','Q3_Canada','Q3_Switzerland',\n",
        "                                'Q3_Russia','Q3_South Africa','Q3_Netherlands','Q3_Pakistan',\n",
        "                                'Q3_Indonesia','Q3_Belarus','Q3_Ukraine','Q3_Saudi Arabia',\n",
        "                                'Q3_Taiwan','Q3_China','Q3_Italy','Q3_UAE','Q3_Colombia',\n",
        "                                'Q3_Viet Nam','Q3_UK','Q3_Egypt','Q3_Brazil','Q3_Mexico',\n",
        "                                'Q3_Poland','Q3_Nigeria','Q3_France','Q3_Belgium','Q3_Turkey',\n",
        "                                'Q3_Spain','Q3_Iran','Q3_Japan','Q3_Tunisia','Q3_Romania',\n",
        "                                'Q3_Republic of Korea','Q3_Chile','Q3_Ireland','Q3_Sweden',\n",
        "                                'Q3_Greece','Q3_Australia','Q3_Malaysia','Q3_Philippines',\n",
        "                                'Q3_Nepal','Q3_Kenya','Q3_South Korea','Q3_Morocco','Q3_Portugal',\n",
        "                                'Q3_Thailand','Q3_Peru','Q3_Bangladesh','Q3_Israel','Q3_Sri Lanka',\n",
        "                                'Q3_Singapore','Q3_Ghana'],axis=1)\n",
        "\n",
        "df_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10729, 457)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxjmdCZSfcMP"
      },
      "source": [
        "#feature selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "# WARNING: This block runs for some time (5mins in GoogleColab) because of feature volumes.\n",
        "\n",
        "\n",
        "# Use L1 LogisticRegression to select features\n",
        "# because there are 15 salary buckets, the for loop runs for 15-1 = 14 times, each time changing class labels to only 0 and 1 and shuffling data\n",
        "# SelectFromModel selects features with non-zero coefficients\n",
        "# .get_support gives a boolean value of whether a feature is selected, they are recorded for each loop in the selector_list\n",
        "\n",
        "selector_list = []\n",
        "for i in range(14):\n",
        "    y_train_copy = y_train.copy()\n",
        "    y_train_copy = y_train_copy['Q24_Encoded']\n",
        "\n",
        "    y_train_copy[y_train_copy <= i] = 0\n",
        "    y_train_copy[y_train_copy > i] = 1\n",
        "\n",
        "    clf = LogisticRegression(penalty='l1', tol=0.001, C=1.0, random_state=0, solver='saga', max_iter=500).fit(X_train, y_train_copy)\n",
        "    selector = SelectFromModel(clf, prefit=True)\n",
        "    temp = selector.get_support()\n",
        "    selector_list.append(temp)\n",
        "\n",
        "\n",
        "# put the selector result in a df\n",
        "df_selector = pd.DataFrame(list(zip(selector_list[0],selector_list[1],selector_list[2],\n",
        "                                    selector_list[3],selector_list[4],selector_list[5],\n",
        "                                    selector_list[6],selector_list[7],selector_list[8],\n",
        "                                    selector_list[9],selector_list[10],selector_list[11],\n",
        "                                    selector_list[12],selector_list[13])), \n",
        "                           columns=['run1','run2','run3','run4','run5','run6','run7','run8',\n",
        "                                    'run9','run10','run11','run12','run13','run14',])\n",
        "\n",
        "\n",
        "# only features that are selected for all 14 loops during logistic regression are kept\n",
        "df_selector['selected'] = np.nan\n",
        "df_selector.loc[df_selector.sum(axis=1)==14,['selected']] = True\n",
        "df_selector=df_selector.fillna(False)\n",
        "\n",
        "# discarding features not selected for X_train and X_test\n",
        "X_train = X_train.iloc[:,df_selector['selected'].to_list()]\n",
        "X_test = X_test.iloc[:,df_selector['selected'].to_list()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbReUp55f9Oe",
        "outputId": "c825b26c-89e9-4e89-a547-bfdc1414803c"
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Q1', 'Q2_Man', 'Q2_Woman', 'Q3_US', 'Q3_India', 'Q3_UK', 'Q3_Spain',\n",
              "       'Q3_Australia', 'Q3_Israel', 'Q4', 'Q5_Other', 'Q5_Data Analyst', 'Q6',\n",
              "       'Q7_Part_7', 'Q7_OTHER', 'Q9_Part_3', 'Q9_Part_5', 'Q9_Part_7',\n",
              "       'Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13',\n",
              "       'Q11_A personal computer or laptop',\n",
              "       'Q11_A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)',\n",
              "       'Q12_Part_1', 'Q12_Part_3', 'Q13', 'Q14_Part_2', 'Q14_Part_9', 'Q15',\n",
              "       'Q16_Part_2', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_12', 'Q20', 'Q21',\n",
              "       'Q22', 'Q23_Part_3', 'Q23_Part_6', 'Q23_OTHER', 'Q25', 'Q26_A_Part_11',\n",
              "       'Q27_A_Part_10', 'Q29_A_Part_6', 'Q29_A_Part_7', 'Q29_A_Part_8',\n",
              "       'Q29_A_Part_10', 'Q29_A_Part_16', 'Q30_PostgresSQL ',\n",
              "       'Q30_Microsoft SQL Server', 'Q31_MISSING', 'Q33_A_Part_2',\n",
              "       'Q33_A_Part_7', 'Q36_Part_9', 'Q37_Part_3', 'Q37_Part_7', 'Q37_Part_8',\n",
              "       'Q38_Basic statistical software (Microsoft Excel, Google Sheets, etc.)',\n",
              "       'Q38_Local development environments (RStudio, JupyterLab, etc.)',\n",
              "       'Q38_Cloud-based data software & APIs (AWS, GCP, Azure, etc.)',\n",
              "       'Q39_Part_8', 'Q39_Part_9', 'Q28_B_Part_8', 'Q29_B_Part_17',\n",
              "       'Q31_B_Part_1'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu35q4dQeHs5",
        "outputId": "7d3a9854-2a10-415d-9fa9-8f8aa5c0cde4"
      },
      "source": [
        "len(X_train.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGVAv8emF-AV"
      },
      "source": [
        "# Model Implementation and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXXahy2U30BV"
      },
      "source": [
        "The model used for prediction is the same model used for feature selection, the ordinal logistic regression as described in the last section. However this time, instead of selecting features, the algorithm predicts the probability of each sample belonging to each salary bucket. The algorithm is then used in a 10-fold cross-validation function, and the model accuracies of each fold are calculated. The model accuracies across the different folds are relatively consistent, ranging from 0.415 to 0.450, the average accuracy is about 0.439, with a very low variance of 0.0002.\n",
        "\n",
        "The hyperparameters in the models are the norm used for penalization (penalty), dual or primal formulation (dual), tolerance for stopping criteria (tol), inverse of regularization strength (C), whether or not to have a bias term added to the decision function (fit_intercept), weight associated with different classes (class_weight), maximum iteration (max_iter), whether or not to reuse solution of the previous call to fit as initialization (warm_start), and when using ‘elasticnet’ as the penalty term, what ratio of L1 norm should be used (l1_ratio). Solver and solver-related parameters are not considered hyperparameters because different solvers have their own advantages and limitations, and solver ‘saga’ is used because it works with all types of penalty terms. \n",
        "\n",
        "The two hyperparameters chosen to perform grid search are L1_ratio and C.  L1_ratio is only used with the penalty ‘elesticnet’, which is a mix of L1 and L2 penalties. L1_ratio specifies the ratio of L1 norm in the mixture and can be between 0 and 1. if L1_ratio=0, it is equivalent to using the L2 norm as the penalty. Inverse of Regularization strength C is a positive float which specifies the degree of penalty; the smaller C is, the stronger the strength of the regularization.\n",
        "\n",
        "The performance measure selected to choose the best model is the accuracy score, which computes the fraction where the predicted label exactly matches the true label. It is used because the target has multiple classes, and we are interested in the overall prediction accuracy. It is the same as the f1 score using ‘micro’ average. \n",
        "\n",
        "The result of the grid search shows that the best model is to use L1_ratio = 0.1, and C = 0.01. This combination of hyperparameters gives an average cross validation accuracy of 0.443, it should be noted that the improvement is very small from before the implementation of grid search, (from 0.439 to 0.443), and the difference of accuracy between different combinations are also very small. Based on bias-variance trade-off, the small L1_ratio shows that the model performs better with mostly L2 norm penalty, which makes the model more complex than if L1_ratio was higher. The regularization strength is relatively strong, which suggests a tendency to make the model less complex. These two parameters work well because they balance out the complexity of the model and prediction accuracies. \n",
        "\n",
        "In order to determine whether scaling and regularizing features can improve the model, two types of transformations are applied to the training data.  The first one is MinMaxScaler, it scales each feature individually such that it is between 0 and 1, it could potentially be helpful because it scales all the ordinal features to be between 0 and 1 but does not change binary features. The second one is StandardScaler, which standardizes the entire dataset by subtracting the mean and divide by the standard deviation. The scaled and standardized features are used for prediction again, however, the resulting accuracy did not show improvement, and cross-validation accuracy still remains at around 0.44. It appears that standardizing and scaling features are not necessary in this case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D5jZRNsQlrD"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tzL3x6kKJAx"
      },
      "source": [
        "# Ordinal logistic regression implemented using binary logistic regression classifier\n",
        "# The output of this function is a dataframe that presents the probability of each sample belonging to a particular salary bucket\n",
        "# The two hyperparameters selected to be tuned are: L1_ratio and c\n",
        "\n",
        "def ordinal_logistic_regression(X_train, y_train, X_test, L1_ratio, c):\n",
        "    proba_list = [np.zeros(len(X_test))]\n",
        "    for i in range(14):\n",
        "        y_train_copy = y_train.copy()\n",
        "        y_train_copy = y_train_copy['Q24_Encoded']\n",
        "\n",
        "        y_train_copy[y_train_copy <= i] = 0\n",
        "        y_train_copy[y_train_copy > i] = 1\n",
        "\n",
        "        clf = LogisticRegression(penalty='elasticnet', tol=0.001, C=c, random_state=0, solver='saga', max_iter=600, l1_ratio=L1_ratio).fit(X_train, y_train_copy)\n",
        "        proba = clf.predict_proba(X_test)\n",
        "        proba_list.append(proba[:,0])\n",
        "    proba_list.append(np.ones(len(X_test)))\n",
        "    \n",
        "    proba_bucket_list = []\n",
        "    for i in range(15):\n",
        "      prob_bucket = proba_list[i+1] - proba_list[i]\n",
        "      proba_bucket_list.append(prob_bucket)\n",
        "    \n",
        "    df_proba_bucket = pd.DataFrame(list(zip(proba_bucket_list[0],proba_bucket_list[1],proba_bucket_list[2],\n",
        "                                    proba_bucket_list[3],proba_bucket_list[4],proba_bucket_list[5],\n",
        "                                    proba_bucket_list[6],proba_bucket_list[7],proba_bucket_list[8],\n",
        "                                    proba_bucket_list[9],proba_bucket_list[10],proba_bucket_list[11],\n",
        "                                    proba_bucket_list[12],proba_bucket_list[13],proba_bucket_list[14])), \n",
        "                           columns=['0-9,999','10,000-19,999','20,000-29,999','30,000-39,999','40,000-49,999','50,000-59,999',\n",
        "                                    '60,000-69,999','70,000-79,999','80,000-89,999','90,000-99,999','100,000-124,999',\n",
        "                                    '125,000-149,999','150,000-199,999','200,000-249,999','>250,000'])\n",
        "    \n",
        "    return df_proba_bucket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHptIRzbQfrU"
      },
      "source": [
        "#ordinal logistic regression with Cross Validation\n",
        "#the output of this function is the accuracy score for each fold\n",
        "#folds = 10\n",
        "\n",
        "def ten_fold_ordlogit(X, y, L1_ratio, c ):\n",
        "    \n",
        "    kf = KFold(n_splits=10)\n",
        "    \n",
        "    accuracy_outcome = []\n",
        "    fold = 0\n",
        "    \n",
        "    for train_index, test_index in kf.split(X):\n",
        "        fold += 1\n",
        "        X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
        "        y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
        "\n",
        "        y_proba = ordinal_logistic_regression(X_train, y_train, X_test, c, L1_ratio)\n",
        "        y_pred = y_proba.idxmax(axis='columns')\n",
        "        \n",
        "        accuracy = accuracy_score(y_test['Q24_buckets'], y_pred)\n",
        "        accuracy_outcome.append(accuracy)\n",
        "\n",
        "    return(accuracy_outcome)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6jH11KDko16",
        "outputId": "e85ef51a-b1db-4920-dce5-9f2f9b346f6a"
      },
      "source": [
        "#This code block runs for about 5mins, therefore it is commented out, the oupput is still visiable\n",
        "#apply the ordinal logistic regression with cross validation on the training set\n",
        "#the results are visible below, mean accuracy is around 0.44\n",
        "\n",
        "accuracy_outcome = ten_fold_ordlogit(X_train, y_train, L1_ratio=1.0, c=1.0)\n",
        "\n",
        "for i in range(len(accuracy_outcome)):\n",
        "    print(f\"Fold {i+1} accuracy: {accuracy_outcome[i]}\")\n",
        "\n",
        "mean_accuracy = np.mean(accuracy_outcome)\n",
        "var_accuracy = np.var(accuracy_outcome)\n",
        "print(f\"\\nMean of accuracy: {mean_accuracy}\") \n",
        "print(f\"Variance of accuracy: {var_accuracy}\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1 accuracy: 0.45006657789613846\n",
            "Fold 2 accuracy: 0.41544607190412786\n",
            "Fold 3 accuracy: 0.44873501997336884\n",
            "Fold 4 accuracy: 0.4207723035952064\n",
            "Fold 5 accuracy: 0.4181091877496671\n",
            "Fold 6 accuracy: 0.44607190412782954\n",
            "Fold 7 accuracy: 0.43275632490013316\n",
            "Fold 8 accuracy: 0.4540612516644474\n",
            "Fold 9 accuracy: 0.4434087882822903\n",
            "Fold 10 accuracy: 0.4607190412782956\n",
            "\n",
            "Mean of accuracy: 0.4390146471371505\n",
            "Variance of accuracy: 0.00023476908728885213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2G4tWk4L07P"
      },
      "source": [
        "def grid_search (l1_ratio_list, C_list):\n",
        "\n",
        "    accuracy_list = []\n",
        "    Hparam_list = []\n",
        "\n",
        "    for l1 in l1_ratio_list:\n",
        "        for C in C_list:\n",
        "            Hparam_list.append([l1,C])\n",
        "            accuracy_outcome = ten_fold_ordlogit(X_train, y_train, L1_ratio=l1, c=C)\n",
        "            accuracy_list.append(np.mean(accuracy_outcome))\n",
        "            print(f'L1 ratio: {l1}, C: {C}')\n",
        "            print(f'accuracy: {np.mean(accuracy_outcome)}\\n')\n",
        "\n",
        "    \n",
        "    return Hparam_list, accuracy_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1347
        },
        "id": "doq0oIyjSRme",
        "outputId": "293c16a7-e18c-424c-afec-903697c00cba"
      },
      "source": [
        "# #grid search runs for a very long time, therefore it is commented out, the oupput is still visiable\n",
        "\n",
        "# l1_ratio_list = [0.1, 0.4, 0.7, 1.0]\n",
        "# C_list = [1.0, 0.1, 0.01, 0.001]\n",
        "\n",
        "# #use the grid search function defined above\n",
        "# Hparam_list, accuracy_list = grid_search(l1_ratio_list, C_list)\n",
        "\n",
        "\n",
        "# #turn grid search result into a df and rank by descending accuracy\n",
        "# #the best values for the chosed hyperparameters are l1_ratio=0,1, c=0.01\n",
        "# df_gridsearch = pd.DataFrame(list(zip(Hparam_list, accuracy_list)), \n",
        "#                             columns=['[l1, C]', 'accuracy'])\n",
        "\n",
        "# df_gridsearch.sort_values(by=['accuracy'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1 ratio: 0.1, C: 1.0\n",
            "accuracy: 0.43981358189081227\n",
            "\n",
            "L1 ratio: 0.1, C: 0.1\n",
            "accuracy: 0.44234354194407455\n",
            "\n",
            "L1 ratio: 0.1, C: 0.01\n",
            "accuracy: 0.44354194407456726\n",
            "\n",
            "L1 ratio: 0.1, C: 0.001\n",
            "accuracy: 0.44340878828229024\n",
            "\n",
            "L1 ratio: 0.4, C: 1.0\n",
            "accuracy: 0.4394141145139813\n",
            "\n",
            "L1 ratio: 0.4, C: 0.1\n",
            "accuracy: 0.44007989347536614\n",
            "\n",
            "L1 ratio: 0.4, C: 0.01\n",
            "accuracy: 0.440745672436751\n",
            "\n",
            "L1 ratio: 0.4, C: 0.001\n",
            "accuracy: 0.4410119840213049\n",
            "\n",
            "L1 ratio: 0.7, C: 1.0\n",
            "accuracy: 0.43808255659121176\n",
            "\n",
            "L1 ratio: 0.7, C: 0.1\n",
            "accuracy: 0.43994673768308923\n",
            "\n",
            "L1 ratio: 0.7, C: 0.01\n",
            "accuracy: 0.44034620505992017\n",
            "\n",
            "L1 ratio: 0.7, C: 0.001\n",
            "accuracy: 0.44034620505992017\n",
            "\n",
            "L1 ratio: 1.0, C: 1.0\n",
            "accuracy: 0.4390146471371505\n",
            "\n",
            "L1 ratio: 1.0, C: 0.1\n",
            "accuracy: 0.44047936085219713\n",
            "\n",
            "L1 ratio: 1.0, C: 0.01\n",
            "accuracy: 0.4395472703062584\n",
            "\n",
            "L1 ratio: 1.0, C: 0.001\n",
            "accuracy: 0.43968042609853536\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[l1, C]</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.1, 0.01]</td>\n",
              "      <td>0.443542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.1, 0.001]</td>\n",
              "      <td>0.443409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.1, 0.1]</td>\n",
              "      <td>0.442344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[0.4, 0.001]</td>\n",
              "      <td>0.441012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[0.4, 0.01]</td>\n",
              "      <td>0.440746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[1.0, 0.1]</td>\n",
              "      <td>0.440479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[0.7, 0.01]</td>\n",
              "      <td>0.440346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[0.7, 0.001]</td>\n",
              "      <td>0.440346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0.4, 0.1]</td>\n",
              "      <td>0.440080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[0.7, 0.1]</td>\n",
              "      <td>0.439947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.1, 1.0]</td>\n",
              "      <td>0.439814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[1.0, 0.001]</td>\n",
              "      <td>0.439680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[1.0, 0.01]</td>\n",
              "      <td>0.439547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.4, 1.0]</td>\n",
              "      <td>0.439414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[1.0, 1.0]</td>\n",
              "      <td>0.439015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0.7, 1.0]</td>\n",
              "      <td>0.438083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         [l1, C]  accuracy\n",
              "2    [0.1, 0.01]  0.443542\n",
              "3   [0.1, 0.001]  0.443409\n",
              "1     [0.1, 0.1]  0.442344\n",
              "7   [0.4, 0.001]  0.441012\n",
              "6    [0.4, 0.01]  0.440746\n",
              "13    [1.0, 0.1]  0.440479\n",
              "10   [0.7, 0.01]  0.440346\n",
              "11  [0.7, 0.001]  0.440346\n",
              "5     [0.4, 0.1]  0.440080\n",
              "9     [0.7, 0.1]  0.439947\n",
              "0     [0.1, 1.0]  0.439814\n",
              "15  [1.0, 0.001]  0.439680\n",
              "14   [1.0, 0.01]  0.439547\n",
              "4     [0.4, 1.0]  0.439414\n",
              "12    [1.0, 1.0]  0.439015\n",
              "8     [0.7, 1.0]  0.438083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3G_DabyL76W"
      },
      "source": [
        "### Experiment with regularized features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEO7z8X1OOjD"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "58yAJxvAOE83",
        "outputId": "4e7365e7-8766-4083-de2f-3ca4ea643a77"
      },
      "source": [
        "#transform features with MinMaxScaler (only experimenting with training dataset)\n",
        "#MinMaxScaler scales and translates each feature individually such that it is between 0 and 1.\n",
        "#This could potentially be helpful because it scales all the ordinal features to be between 0 and 1 but does not change binary features\n",
        "scaler = MinMaxScaler()\n",
        "scaled_X_train = scaler.fit_transform(X_train)\n",
        "scaled_X_train_df = pd.DataFrame(scaled_X_train, columns=X_train.columns)\n",
        "scaled_X_train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2_Man</th>\n",
              "      <th>Q2_Woman</th>\n",
              "      <th>Q3_US</th>\n",
              "      <th>Q3_India</th>\n",
              "      <th>Q3_UK</th>\n",
              "      <th>Q3_Spain</th>\n",
              "      <th>Q3_Australia</th>\n",
              "      <th>Q3_Israel</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5_Other</th>\n",
              "      <th>Q5_Data Analyst</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7_Part_7</th>\n",
              "      <th>Q7_OTHER</th>\n",
              "      <th>Q9_Part_3</th>\n",
              "      <th>Q9_Part_5</th>\n",
              "      <th>Q9_Part_7</th>\n",
              "      <th>Q10_Part_11</th>\n",
              "      <th>Q10_Part_12</th>\n",
              "      <th>Q10_Part_13</th>\n",
              "      <th>Q11_A personal computer or laptop</th>\n",
              "      <th>Q11_A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)</th>\n",
              "      <th>Q12_Part_1</th>\n",
              "      <th>Q12_Part_3</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14_Part_2</th>\n",
              "      <th>Q14_Part_9</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16_Part_2</th>\n",
              "      <th>Q16_Part_7</th>\n",
              "      <th>Q16_Part_8</th>\n",
              "      <th>Q16_Part_12</th>\n",
              "      <th>Q20</th>\n",
              "      <th>Q21</th>\n",
              "      <th>Q22</th>\n",
              "      <th>Q23_Part_3</th>\n",
              "      <th>Q23_Part_6</th>\n",
              "      <th>Q23_OTHER</th>\n",
              "      <th>Q25</th>\n",
              "      <th>Q26_A_Part_11</th>\n",
              "      <th>Q27_A_Part_10</th>\n",
              "      <th>Q29_A_Part_6</th>\n",
              "      <th>Q29_A_Part_7</th>\n",
              "      <th>Q29_A_Part_8</th>\n",
              "      <th>Q29_A_Part_10</th>\n",
              "      <th>Q29_A_Part_16</th>\n",
              "      <th>Q30_PostgresSQL</th>\n",
              "      <th>Q30_Microsoft SQL Server</th>\n",
              "      <th>Q31_MISSING</th>\n",
              "      <th>Q33_A_Part_2</th>\n",
              "      <th>Q33_A_Part_7</th>\n",
              "      <th>Q36_Part_9</th>\n",
              "      <th>Q37_Part_3</th>\n",
              "      <th>Q37_Part_7</th>\n",
              "      <th>Q37_Part_8</th>\n",
              "      <th>Q38_Basic statistical software (Microsoft Excel, Google Sheets, etc.)</th>\n",
              "      <th>Q38_Local development environments (RStudio, JupyterLab, etc.)</th>\n",
              "      <th>Q38_Cloud-based data software &amp; APIs (AWS, GCP, Azure, etc.)</th>\n",
              "      <th>Q39_Part_8</th>\n",
              "      <th>Q39_Part_9</th>\n",
              "      <th>Q28_B_Part_8</th>\n",
              "      <th>Q29_B_Part_17</th>\n",
              "      <th>Q31_B_Part_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7505</th>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7506</th>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7507</th>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7508</th>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7509</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7510 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Q1  Q2_Man  Q2_Woman  ...  Q28_B_Part_8  Q29_B_Part_17  Q31_B_Part_1\n",
              "0     0.2     1.0       0.0  ...           0.0            0.0           0.0\n",
              "1     0.4     1.0       0.0  ...           0.0            0.0           0.0\n",
              "2     0.1     0.0       1.0  ...           0.0            0.0           0.0\n",
              "3     0.4     1.0       0.0  ...           0.0            0.0           0.0\n",
              "4     0.3     1.0       0.0  ...           0.0            0.0           0.0\n",
              "...   ...     ...       ...  ...           ...            ...           ...\n",
              "7505  0.2     1.0       0.0  ...           0.0            0.0           0.0\n",
              "7506  0.3     1.0       0.0  ...           0.0            0.0           1.0\n",
              "7507  0.6     1.0       0.0  ...           0.0            0.0           0.0\n",
              "7508  0.2     1.0       0.0  ...           0.0            0.0           0.0\n",
              "7509  0.4     0.0       0.0  ...           1.0            1.0           0.0\n",
              "\n",
              "[7510 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p8L0ureMCNr",
        "outputId": "0a2c41bd-3a66-4675-f581-e32ba0be592d"
      },
      "source": [
        "#run ordinal logistic regression with CV with scaled features\n",
        "#the result does not seem to change much from unscaled features\n",
        "scaled_accuracy_outcome = ten_fold_ordlogit(scaled_X_train_df, y_train, L1_ratio=0.1, c=0.01)\n",
        "\n",
        "for i in range(len(scaled_accuracy_outcome)):\n",
        "    print(f\"Fold {i+1} accuracy: {scaled_accuracy_outcome[i]}\")\n",
        "\n",
        "mean_accuracy_scaled = np.mean(scaled_accuracy_outcome)\n",
        "var_accuracy_scaled = np.var(scaled_accuracy_outcome)\n",
        "print(f\"\\nMean of accuracy: {mean_accuracy_scaled}\") \n",
        "print(f\"Variance of accuracy: {var_accuracy_scaled}\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1 accuracy: 0.45539280958721706\n",
            "Fold 2 accuracy: 0.4141145139813582\n",
            "Fold 3 accuracy: 0.45006657789613846\n",
            "Fold 4 accuracy: 0.43142476697736354\n",
            "Fold 5 accuracy: 0.4181091877496671\n",
            "Fold 6 accuracy: 0.4580559254327563\n",
            "Fold 7 accuracy: 0.440745672436751\n",
            "Fold 8 accuracy: 0.4447403462050599\n",
            "Fold 9 accuracy: 0.4394141145139814\n",
            "Fold 10 accuracy: 0.47137150466045274\n",
            "\n",
            "Mean of accuracy: 0.44234354194407455\n",
            "Variance of accuracy: 0.0002839711277107666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "bb5mf1gNRuVm",
        "outputId": "40bd0957-fa2b-4eb7-8ed5-e0db29060069"
      },
      "source": [
        "#transform features with StandardScaler to standarize the entire dataset\n",
        "std_scalar = StandardScaler()\n",
        "std_X_train = std_scalar.fit_transform(scaled_X_train)\n",
        "std_X_train_df = pd.DataFrame(std_X_train, columns=X_train.columns)\n",
        "std_X_train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2_Man</th>\n",
              "      <th>Q2_Woman</th>\n",
              "      <th>Q3_US</th>\n",
              "      <th>Q3_India</th>\n",
              "      <th>Q3_UK</th>\n",
              "      <th>Q3_Spain</th>\n",
              "      <th>Q3_Australia</th>\n",
              "      <th>Q3_Israel</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5_Other</th>\n",
              "      <th>Q5_Data Analyst</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7_Part_7</th>\n",
              "      <th>Q7_OTHER</th>\n",
              "      <th>Q9_Part_3</th>\n",
              "      <th>Q9_Part_5</th>\n",
              "      <th>Q9_Part_7</th>\n",
              "      <th>Q10_Part_11</th>\n",
              "      <th>Q10_Part_12</th>\n",
              "      <th>Q10_Part_13</th>\n",
              "      <th>Q11_A personal computer or laptop</th>\n",
              "      <th>Q11_A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)</th>\n",
              "      <th>Q12_Part_1</th>\n",
              "      <th>Q12_Part_3</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14_Part_2</th>\n",
              "      <th>Q14_Part_9</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16_Part_2</th>\n",
              "      <th>Q16_Part_7</th>\n",
              "      <th>Q16_Part_8</th>\n",
              "      <th>Q16_Part_12</th>\n",
              "      <th>Q20</th>\n",
              "      <th>Q21</th>\n",
              "      <th>Q22</th>\n",
              "      <th>Q23_Part_3</th>\n",
              "      <th>Q23_Part_6</th>\n",
              "      <th>Q23_OTHER</th>\n",
              "      <th>Q25</th>\n",
              "      <th>Q26_A_Part_11</th>\n",
              "      <th>Q27_A_Part_10</th>\n",
              "      <th>Q29_A_Part_6</th>\n",
              "      <th>Q29_A_Part_7</th>\n",
              "      <th>Q29_A_Part_8</th>\n",
              "      <th>Q29_A_Part_10</th>\n",
              "      <th>Q29_A_Part_16</th>\n",
              "      <th>Q30_PostgresSQL</th>\n",
              "      <th>Q30_Microsoft SQL Server</th>\n",
              "      <th>Q31_MISSING</th>\n",
              "      <th>Q33_A_Part_2</th>\n",
              "      <th>Q33_A_Part_7</th>\n",
              "      <th>Q36_Part_9</th>\n",
              "      <th>Q37_Part_3</th>\n",
              "      <th>Q37_Part_7</th>\n",
              "      <th>Q37_Part_8</th>\n",
              "      <th>Q38_Basic statistical software (Microsoft Excel, Google Sheets, etc.)</th>\n",
              "      <th>Q38_Local development environments (RStudio, JupyterLab, etc.)</th>\n",
              "      <th>Q38_Cloud-based data software &amp; APIs (AWS, GCP, Azure, etc.)</th>\n",
              "      <th>Q39_Part_8</th>\n",
              "      <th>Q39_Part_9</th>\n",
              "      <th>Q28_B_Part_8</th>\n",
              "      <th>Q29_B_Part_17</th>\n",
              "      <th>Q31_B_Part_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.651701</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>0.187823</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>0.478438</td>\n",
              "      <td>2.225055</td>\n",
              "      <td>2.598126</td>\n",
              "      <td>2.541219</td>\n",
              "      <td>-0.626329</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>1.373809</td>\n",
              "      <td>0.640569</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>-0.954687</td>\n",
              "      <td>1.026995</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>-1.009096</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>0.833462</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>1.466600</td>\n",
              "      <td>1.625620</td>\n",
              "      <td>0.896038</td>\n",
              "      <td>1.313755</td>\n",
              "      <td>1.918866</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>-0.417473</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>3.960920</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>2.434758</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>1.119475</td>\n",
              "      <td>-0.526921</td>\n",
              "      <td>1.524624</td>\n",
              "      <td>1.480429</td>\n",
              "      <td>2.846582</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>-0.815817</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>-0.853710</td>\n",
              "      <td>2.075433</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.251885</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>0.187823</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>1.079286</td>\n",
              "      <td>2.225055</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>2.541219</td>\n",
              "      <td>-0.626329</td>\n",
              "      <td>2.023606</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>1.373809</td>\n",
              "      <td>-1.561112</td>\n",
              "      <td>3.970314</td>\n",
              "      <td>1.047463</td>\n",
              "      <td>-0.973714</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>-1.009096</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>0.833462</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>-1.077528</td>\n",
              "      <td>-0.699614</td>\n",
              "      <td>0.896038</td>\n",
              "      <td>-0.761177</td>\n",
              "      <td>1.918866</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>1.383000</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>1.119475</td>\n",
              "      <td>1.897819</td>\n",
              "      <td>-0.655899</td>\n",
              "      <td>-0.675480</td>\n",
              "      <td>-0.351298</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>1.225765</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>1.171357</td>\n",
              "      <td>2.075433</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.103494</td>\n",
              "      <td>-2.195838</td>\n",
              "      <td>2.343272</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>0.187823</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>-0.122410</td>\n",
              "      <td>2.225055</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>2.541219</td>\n",
              "      <td>1.596606</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>-0.727903</td>\n",
              "      <td>0.640569</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>1.047463</td>\n",
              "      <td>-0.973714</td>\n",
              "      <td>1.512261</td>\n",
              "      <td>0.990986</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>-0.676501</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>1.466600</td>\n",
              "      <td>1.625620</td>\n",
              "      <td>-0.290568</td>\n",
              "      <td>1.313755</td>\n",
              "      <td>1.918866</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>-0.417473</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>2.434758</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>4.386637</td>\n",
              "      <td>-0.893275</td>\n",
              "      <td>-0.526921</td>\n",
              "      <td>1.524624</td>\n",
              "      <td>1.480429</td>\n",
              "      <td>2.846582</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>1.225765</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>1.171357</td>\n",
              "      <td>2.075433</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.251885</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>2.477657</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>1.170102</td>\n",
              "      <td>2.511065</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>1.079286</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>1.596606</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>1.373809</td>\n",
              "      <td>0.640569</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>-0.954687</td>\n",
              "      <td>1.026995</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>0.990986</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>1.336783</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>3.621677</td>\n",
              "      <td>1.466600</td>\n",
              "      <td>1.625620</td>\n",
              "      <td>1.489341</td>\n",
              "      <td>1.313755</td>\n",
              "      <td>-0.521141</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>1.383000</td>\n",
              "      <td>2.195838</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>2.434758</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>4.319686</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>1.119475</td>\n",
              "      <td>1.897819</td>\n",
              "      <td>-0.655899</td>\n",
              "      <td>-0.675480</td>\n",
              "      <td>-0.351298</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>-0.815817</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>1.171357</td>\n",
              "      <td>-0.481827</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.199908</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>-0.794456</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>-0.723257</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>1.596606</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>5.677155</td>\n",
              "      <td>-0.727903</td>\n",
              "      <td>-1.561112</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>1.047463</td>\n",
              "      <td>-0.973714</td>\n",
              "      <td>0.471473</td>\n",
              "      <td>-1.009096</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>-0.676501</td>\n",
              "      <td>-0.849290</td>\n",
              "      <td>1.708092</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>0.830568</td>\n",
              "      <td>0.695527</td>\n",
              "      <td>-0.883871</td>\n",
              "      <td>-0.761177</td>\n",
              "      <td>-0.521141</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>0.782842</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>1.119475</td>\n",
              "      <td>-0.526921</td>\n",
              "      <td>-0.655899</td>\n",
              "      <td>1.480429</td>\n",
              "      <td>2.846582</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>-0.815817</td>\n",
              "      <td>4.255516</td>\n",
              "      <td>-0.853710</td>\n",
              "      <td>-0.481827</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7505</th>\n",
              "      <td>-0.651701</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>0.187823</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>-0.122410</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>-0.626329</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>-0.727903</td>\n",
              "      <td>-1.561112</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>-0.954687</td>\n",
              "      <td>1.026995</td>\n",
              "      <td>1.512261</td>\n",
              "      <td>0.990986</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>-0.173180</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>1.708092</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>-0.441496</td>\n",
              "      <td>-0.234567</td>\n",
              "      <td>-0.883871</td>\n",
              "      <td>-0.761177</td>\n",
              "      <td>-0.521141</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>0.782842</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>1.119475</td>\n",
              "      <td>1.897819</td>\n",
              "      <td>1.524624</td>\n",
              "      <td>-0.675480</td>\n",
              "      <td>-0.351298</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>1.225765</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>-0.853710</td>\n",
              "      <td>-0.481827</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7506</th>\n",
              "      <td>-0.199908</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>0.187823</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>2.734282</td>\n",
              "      <td>-1.324105</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>1.596606</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>-0.727903</td>\n",
              "      <td>0.640569</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>-0.954687</td>\n",
              "      <td>1.026995</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>0.990986</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>-0.676501</td>\n",
              "      <td>-0.849290</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>0.194536</td>\n",
              "      <td>-0.699614</td>\n",
              "      <td>-0.883871</td>\n",
              "      <td>-0.761177</td>\n",
              "      <td>-0.521141</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>-1.017631</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>-0.893275</td>\n",
              "      <td>-0.526921</td>\n",
              "      <td>-0.655899</td>\n",
              "      <td>1.480429</td>\n",
              "      <td>-0.351298</td>\n",
              "      <td>1.659254</td>\n",
              "      <td>-0.815817</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>-0.853710</td>\n",
              "      <td>2.075433</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>2.508239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7507</th>\n",
              "      <td>1.155471</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>2.477657</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>-0.794456</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>0.478438</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>2.598126</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>-0.626329</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>1.373809</td>\n",
              "      <td>0.640569</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>-0.954687</td>\n",
              "      <td>-0.973714</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>-1.009096</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>1.840103</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>1.708092</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>1.466600</td>\n",
              "      <td>1.625620</td>\n",
              "      <td>-1.477175</td>\n",
              "      <td>-0.761177</td>\n",
              "      <td>-0.521141</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>1.983157</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>1.119475</td>\n",
              "      <td>1.897819</td>\n",
              "      <td>-0.655899</td>\n",
              "      <td>1.480429</td>\n",
              "      <td>-0.351298</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>1.225765</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>-0.853710</td>\n",
              "      <td>-0.481827</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7508</th>\n",
              "      <td>-0.651701</td>\n",
              "      <td>0.455407</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>2.477657</td>\n",
              "      <td>-0.533516</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>0.187823</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>-0.122410</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>-0.626329</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>-0.727903</td>\n",
              "      <td>-1.561112</td>\n",
              "      <td>-0.251869</td>\n",
              "      <td>1.047463</td>\n",
              "      <td>-0.973714</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>-1.009096</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>-0.173180</td>\n",
              "      <td>1.177455</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>0.830568</td>\n",
              "      <td>-0.234567</td>\n",
              "      <td>0.302735</td>\n",
              "      <td>1.313755</td>\n",
              "      <td>-0.521141</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>0.182684</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>-0.893275</td>\n",
              "      <td>-0.526921</td>\n",
              "      <td>1.524624</td>\n",
              "      <td>-0.675480</td>\n",
              "      <td>-0.351298</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>-0.815817</td>\n",
              "      <td>4.255516</td>\n",
              "      <td>1.171357</td>\n",
              "      <td>2.075433</td>\n",
              "      <td>-0.344081</td>\n",
              "      <td>-0.260137</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7509</th>\n",
              "      <td>0.251885</td>\n",
              "      <td>-2.195838</td>\n",
              "      <td>-0.426754</td>\n",
              "      <td>-0.403607</td>\n",
              "      <td>1.874359</td>\n",
              "      <td>-0.178938</td>\n",
              "      <td>-0.152644</td>\n",
              "      <td>-0.115579</td>\n",
              "      <td>-0.080203</td>\n",
              "      <td>1.170102</td>\n",
              "      <td>-0.398237</td>\n",
              "      <td>-0.365727</td>\n",
              "      <td>1.079286</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>-0.384893</td>\n",
              "      <td>-0.393512</td>\n",
              "      <td>-0.626329</td>\n",
              "      <td>-0.494167</td>\n",
              "      <td>-0.280834</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>-0.727903</td>\n",
              "      <td>-1.561112</td>\n",
              "      <td>3.970314</td>\n",
              "      <td>1.047463</td>\n",
              "      <td>-0.973714</td>\n",
              "      <td>-0.569315</td>\n",
              "      <td>0.990986</td>\n",
              "      <td>-0.227318</td>\n",
              "      <td>1.336783</td>\n",
              "      <td>-0.849290</td>\n",
              "      <td>-0.585448</td>\n",
              "      <td>-0.380319</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>0.830568</td>\n",
              "      <td>0.695527</td>\n",
              "      <td>0.302735</td>\n",
              "      <td>-0.761177</td>\n",
              "      <td>1.918866</td>\n",
              "      <td>-0.223075</td>\n",
              "      <td>-1.017631</td>\n",
              "      <td>-0.455407</td>\n",
              "      <td>-0.252467</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>-0.156259</td>\n",
              "      <td>-0.410719</td>\n",
              "      <td>-0.204336</td>\n",
              "      <td>-0.151728</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>-0.147542</td>\n",
              "      <td>-0.257207</td>\n",
              "      <td>-0.227965</td>\n",
              "      <td>-0.893275</td>\n",
              "      <td>-0.526921</td>\n",
              "      <td>1.524624</td>\n",
              "      <td>1.480429</td>\n",
              "      <td>2.846582</td>\n",
              "      <td>-0.602681</td>\n",
              "      <td>1.225765</td>\n",
              "      <td>-0.234989</td>\n",
              "      <td>1.171357</td>\n",
              "      <td>2.075433</td>\n",
              "      <td>2.906293</td>\n",
              "      <td>3.844127</td>\n",
              "      <td>-0.398686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7510 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Q1    Q2_Man  Q2_Woman  ...  Q28_B_Part_8  Q29_B_Part_17  Q31_B_Part_1\n",
              "0    -0.651701  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "1     0.251885  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "2    -1.103494 -2.195838  2.343272  ...     -0.344081      -0.260137     -0.398686\n",
              "3     0.251885  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "4    -0.199908  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "...        ...       ...       ...  ...           ...            ...           ...\n",
              "7505 -0.651701  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "7506 -0.199908  0.455407 -0.426754  ...     -0.344081      -0.260137      2.508239\n",
              "7507  1.155471  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "7508 -0.651701  0.455407 -0.426754  ...     -0.344081      -0.260137     -0.398686\n",
              "7509  0.251885 -2.195838 -0.426754  ...      2.906293       3.844127     -0.398686\n",
              "\n",
              "[7510 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNclHXvbSJoi",
        "outputId": "f9a8698b-1c5e-4fa0-a3bd-86a8d72bb4e7"
      },
      "source": [
        "#run ordinal logistic regression with CV with standardized features\n",
        "#the result does not seem to change much from unstandardized features\n",
        "\n",
        "std_accuracy_outcome = ten_fold_ordlogit(std_X_train_df, y_train, L1_ratio=0.1, c=0.01)\n",
        "\n",
        "for i in range(len(std_accuracy_outcome)):\n",
        "    print(f\"Fold {i+1} accuracy: {std_accuracy_outcome[i]}\")\n",
        "\n",
        "mean_accuracy_std = np.mean(std_accuracy_outcome)\n",
        "var_accuracy_std = np.var(std_accuracy_outcome)\n",
        "print(f\"\\nMean of accuracy: {mean_accuracy_std}\") \n",
        "print(f\"Variance of accuracy: {var_accuracy_std}\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1 accuracy: 0.45006657789613846\n",
            "Fold 2 accuracy: 0.4207723035952064\n",
            "Fold 3 accuracy: 0.4474034620505992\n",
            "Fold 4 accuracy: 0.4207723035952064\n",
            "Fold 5 accuracy: 0.4167776298268975\n",
            "Fold 6 accuracy: 0.4474034620505992\n",
            "Fold 7 accuracy: 0.4394141145139814\n",
            "Fold 8 accuracy: 0.44607190412782954\n",
            "Fold 9 accuracy: 0.44607190412782954\n",
            "Fold 10 accuracy: 0.47003994673768307\n",
            "\n",
            "Mean of accuracy: 0.440479360852197\n",
            "Variance of accuracy: 0.00024638254187492553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw-9-YNP9KFm"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-IuHNwv4PXX"
      },
      "source": [
        "The best performing model, with L1_ratio = 0.1 and C = 0.01, is used for predicting the testing data, the test accuracy is 0.425, which is only slightly lower than the training data results, which means the model actually generalizes well from the training data to the test data and not overfitting or under fitting. However, the overall prediction accuracy is not very high. The distribution of true target variable values and their predictions on both the training set and the test set are plotted below. It is clear that the dataset has imbalanced classes, where the majority of respondents belong to the salary bucket of ‘0-9999’. As a result,the algorithm is heavily biased towards the salary bucket ‘0-9999’, it exaggerated the imbalance by making most of the predictions in that same bucket and very few in other buckets. The 0.44 accuracy is therefore limited by the number of respondents who actually belong to that salary bucket. This also explains why the grid search did not help to improve accuracy, because changing the two parameters chosen does not help the model realize there is class imbalance in the dataset.\n",
        "\n",
        "Having this insight, we can possibly improve the model accuracy by taking into consideration the relative class sizes for each salary bucket and take advantage of the hyperparameter class_weight, and set it to ‘balanced’. Or we could choose a country where the salary buckets are more balanced. Overall, there is still room for improvement for this model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZr6KAPcEqxk"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "NsngDcHO9JSX",
        "outputId": "658a88fc-11d3-4671-eb2c-bf7f6a4531fe"
      },
      "source": [
        "y_test_proba = ordinal_logistic_regression(X_train, y_train, X_test, 0.1, 0.01)\n",
        "y_test_proba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0-9,999</th>\n",
              "      <th>10,000-19,999</th>\n",
              "      <th>20,000-29,999</th>\n",
              "      <th>30,000-39,999</th>\n",
              "      <th>40,000-49,999</th>\n",
              "      <th>50,000-59,999</th>\n",
              "      <th>60,000-69,999</th>\n",
              "      <th>70,000-79,999</th>\n",
              "      <th>80,000-89,999</th>\n",
              "      <th>90,000-99,999</th>\n",
              "      <th>100,000-124,999</th>\n",
              "      <th>125,000-149,999</th>\n",
              "      <th>150,000-199,999</th>\n",
              "      <th>200,000-249,999</th>\n",
              "      <th>&gt;250,000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.372158</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.076602</td>\n",
              "      <td>0.069447</td>\n",
              "      <td>0.080637</td>\n",
              "      <td>0.050428</td>\n",
              "      <td>0.048134</td>\n",
              "      <td>0.039541</td>\n",
              "      <td>0.028879</td>\n",
              "      <td>0.013323</td>\n",
              "      <td>0.047881</td>\n",
              "      <td>0.014771</td>\n",
              "      <td>0.017132</td>\n",
              "      <td>0.004381</td>\n",
              "      <td>0.006965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.075991</td>\n",
              "      <td>0.031684</td>\n",
              "      <td>0.043176</td>\n",
              "      <td>0.038989</td>\n",
              "      <td>0.066656</td>\n",
              "      <td>0.070428</td>\n",
              "      <td>0.080138</td>\n",
              "      <td>0.111818</td>\n",
              "      <td>0.052830</td>\n",
              "      <td>0.072217</td>\n",
              "      <td>0.102145</td>\n",
              "      <td>0.047598</td>\n",
              "      <td>0.133654</td>\n",
              "      <td>0.044944</td>\n",
              "      <td>0.027731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.698097</td>\n",
              "      <td>0.115309</td>\n",
              "      <td>0.056618</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.023436</td>\n",
              "      <td>0.020911</td>\n",
              "      <td>0.010007</td>\n",
              "      <td>0.010086</td>\n",
              "      <td>0.007174</td>\n",
              "      <td>0.003808</td>\n",
              "      <td>0.004931</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.002816</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.003619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.836186</td>\n",
              "      <td>0.029360</td>\n",
              "      <td>0.035184</td>\n",
              "      <td>0.016714</td>\n",
              "      <td>0.015173</td>\n",
              "      <td>0.014808</td>\n",
              "      <td>0.006456</td>\n",
              "      <td>0.006337</td>\n",
              "      <td>0.010942</td>\n",
              "      <td>0.003847</td>\n",
              "      <td>0.011494</td>\n",
              "      <td>0.004560</td>\n",
              "      <td>0.004962</td>\n",
              "      <td>0.000971</td>\n",
              "      <td>0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.125197</td>\n",
              "      <td>0.088128</td>\n",
              "      <td>0.073614</td>\n",
              "      <td>0.086152</td>\n",
              "      <td>0.050006</td>\n",
              "      <td>0.096164</td>\n",
              "      <td>0.072531</td>\n",
              "      <td>0.092122</td>\n",
              "      <td>0.038780</td>\n",
              "      <td>0.060595</td>\n",
              "      <td>0.080563</td>\n",
              "      <td>0.045474</td>\n",
              "      <td>0.045172</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.024429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3214</th>\n",
              "      <td>0.112905</td>\n",
              "      <td>0.068582</td>\n",
              "      <td>0.053542</td>\n",
              "      <td>0.049492</td>\n",
              "      <td>0.095621</td>\n",
              "      <td>0.084352</td>\n",
              "      <td>0.085434</td>\n",
              "      <td>0.059029</td>\n",
              "      <td>0.043938</td>\n",
              "      <td>0.052160</td>\n",
              "      <td>0.071933</td>\n",
              "      <td>0.018378</td>\n",
              "      <td>0.095613</td>\n",
              "      <td>0.061432</td>\n",
              "      <td>0.047588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3215</th>\n",
              "      <td>0.899574</td>\n",
              "      <td>0.049779</td>\n",
              "      <td>0.015085</td>\n",
              "      <td>0.007848</td>\n",
              "      <td>0.005053</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.005678</td>\n",
              "      <td>0.001913</td>\n",
              "      <td>0.002849</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.002151</td>\n",
              "      <td>0.002057</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>0.002555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3216</th>\n",
              "      <td>0.414930</td>\n",
              "      <td>0.183035</td>\n",
              "      <td>0.128391</td>\n",
              "      <td>0.064926</td>\n",
              "      <td>0.037051</td>\n",
              "      <td>0.041385</td>\n",
              "      <td>0.036969</td>\n",
              "      <td>0.019625</td>\n",
              "      <td>0.025635</td>\n",
              "      <td>0.010804</td>\n",
              "      <td>0.019921</td>\n",
              "      <td>0.004593</td>\n",
              "      <td>0.006213</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.005599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3217</th>\n",
              "      <td>0.498524</td>\n",
              "      <td>0.238411</td>\n",
              "      <td>0.087383</td>\n",
              "      <td>0.047048</td>\n",
              "      <td>0.030131</td>\n",
              "      <td>0.026556</td>\n",
              "      <td>0.016806</td>\n",
              "      <td>0.013504</td>\n",
              "      <td>0.007850</td>\n",
              "      <td>0.002505</td>\n",
              "      <td>0.012721</td>\n",
              "      <td>0.006940</td>\n",
              "      <td>0.005268</td>\n",
              "      <td>0.000774</td>\n",
              "      <td>0.005578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3218</th>\n",
              "      <td>0.491687</td>\n",
              "      <td>0.137300</td>\n",
              "      <td>0.104350</td>\n",
              "      <td>0.051307</td>\n",
              "      <td>0.053775</td>\n",
              "      <td>0.049926</td>\n",
              "      <td>0.032276</td>\n",
              "      <td>0.019299</td>\n",
              "      <td>0.017366</td>\n",
              "      <td>0.007947</td>\n",
              "      <td>0.016347</td>\n",
              "      <td>0.006051</td>\n",
              "      <td>0.007974</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.003550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3219 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0-9,999  10,000-19,999  ...  200,000-249,999  >250,000\n",
              "0     0.372158       0.129720  ...         0.004381  0.006965\n",
              "1     0.075991       0.031684  ...         0.044944  0.027731\n",
              "2     0.698097       0.115309  ...         0.000648  0.003619\n",
              "3     0.836186       0.029360  ...         0.000971  0.003006\n",
              "4     0.125197       0.088128  ...         0.021071  0.024429\n",
              "...        ...            ...  ...              ...       ...\n",
              "3214  0.112905       0.068582  ...         0.061432  0.047588\n",
              "3215  0.899574       0.049779  ...        -0.000002  0.002555\n",
              "3216  0.414930       0.183035  ...         0.000923  0.005599\n",
              "3217  0.498524       0.238411  ...         0.000774  0.005578\n",
              "3218  0.491687       0.137300  ...         0.000845  0.003550\n",
              "\n",
              "[3219 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC9Xtgj2_E2v",
        "outputId": "df67fbf3-45ab-4bd5-cb78-0342f5d47ac1"
      },
      "source": [
        "y_test_pred = y_test_proba.idxmax(axis='columns')\n",
        "test_accuracy = accuracy_score(y_test['Q24_buckets'], y_test_pred)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.42528735632183906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl36m6xhEtnK"
      },
      "source": [
        "# a helper function for plotting\n",
        "def get_ordered_salary_counts(salary_count_dict, ordered_salary_buckets):\n",
        "  ordered_counts = []\n",
        "  for bucket in ordered_salary_buckets:\n",
        "    ordered_counts.append(salary_count_dict.get(bucket, 0))\n",
        "\n",
        "  return ordered_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "U352Dk678Nyq",
        "outputId": "a797986f-376e-4958-881e-592d23a78a9a"
      },
      "source": [
        "#plotting Test Dataset True Target vs Predicted Target\n",
        "salary_buckets = ['0-9,999', '10,000-19,999', '20,000-29,999', '30,000-39,999',\n",
        "                  '40,000-49,999', '50,000-59,999', '60,000-69,999',\n",
        "                  '70,000-79,999', '80,000-89,999', '90,000-99,999',\n",
        "                  '100,000-124,999', '125,000-149,999', '150,000-199,999',\n",
        "                  '200,000-249,999', '>250,000']\n",
        "test_data_counts = Counter(y_test['Q24_buckets'])\n",
        "test_pred_counts = Counter(y_test_pred) \n",
        "\n",
        "x = np.arange(len(salary_buckets))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, get_ordered_salary_counts(test_data_counts, salary_buckets), width, label='True')\n",
        "rects2 = ax.bar(x + width/2, get_ordered_salary_counts(test_pred_counts, salary_buckets), width, label='Predicted')\n",
        "\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Test Dataset True Target vs Predicted Target')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(salary_buckets)\n",
        "plt.xticks(rotation=90)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "ysYPjyvZGSDb",
        "outputId": "6182666b-690b-4fd5-d505-e3fec9387cfa"
      },
      "source": [
        "#plotting Training Dataset True Target vs Predicted Target\n",
        "#the training set is separted to train and validation at 70:30 to fit the model\n",
        "X_train1,X_validation = X_train.iloc[0:5257,:],X_train.iloc[5257:7510,:]\n",
        "y_train1,y_validation = y_train.iloc[0:5257,:],y_train.iloc[5257:7510,:]\n",
        "\n",
        "y_train_proba = ordinal_logistic_regression(X_train1, y_train1, X_validation, 0.1, 0.01)\n",
        "y_train_pred = y_train_proba.idxmax(axis='columns')\n",
        "\n",
        "train_data_counts = Counter(y_validation['Q24_buckets'])\n",
        "train_pred_counts = Counter(y_train_pred) \n",
        "\n",
        "x = np.arange(len(salary_buckets))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, get_ordered_salary_counts(train_data_counts, salary_buckets), width, label='True')\n",
        "rects2 = ax.bar(x + width/2, get_ordered_salary_counts(train_pred_counts, salary_buckets), width, label='Predicted')\n",
        "\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Training Dataset True Target vs Predicted Target')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(salary_buckets)\n",
        "plt.xticks(rotation=90)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}